import os
import re
import sys
import json
import math
import types
import uuid
import tempfile
import traceback
import subprocess

import vlm_code
import google.generativeai as genai
import time


from dotenv import load_dotenv

import subprocess # ë§¨ ìœ„ìª½ì— ì¶”ê°€ ì•ˆ ë˜ì–´ ìˆë‹¤ë©´ ì¶”ê°€í•  ê²ƒ

def crop_and_resize_video(input_path, output_path):
    """ì˜ìƒì˜ ê°€ë¡œ/ì„¸ë¡œ ì¤‘ ì§§ì€ ìª½ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ì•™ ì •ì‚¬ê°í˜• í¬ë¡­ í›„ 224x224 ë¦¬ì‚¬ì´ì¦ˆ"""
    try:
        cmd = [
            'ffmpeg', '-y', '-i', input_path,
            # ğŸŒŸ [ìˆ˜ì •] ë¬´ì¡°ê±´ 1080ì´ ì•„ë‹ˆë¼, ë™ì ìœ¼ë¡œ ì¤‘ì•™ ì •ì‚¬ê°í˜•ì„ ì¡ìŒ
            '-vf', "crop='min(iw,ih)':'min(iw,ih)':'(iw-min(iw,ih))/2':'(ih-min(iw,ih))/2',scale=224:224",
            '-c:v', 'libx264', '-crf', '23', '-preset', 'fast',
            '-c:a', 'copy',
            output_path
        ]
        subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ [FFmpeg] ë¹„ë””ì˜¤ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return False

# .env íŒŒì¼ì„ ì°¾ì•„ì„œ í™˜ê²½ë³€ìˆ˜ë¡œ ê°•ì œ ë¡œë“œ
load_dotenv('/home/ubuntu/ai-muncheol/backend/.env')
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ mmaction2 drn ëª¨ë“ˆ ë²„ê·¸ íŒ¨ì¹˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def patch_mmaction_drn():
    try:
        drn_pkg = types.ModuleType("mmaction.models.localizers.drn")
        drn_drn = types.ModuleType("mmaction.models.localizers.drn.drn")
        class DRN: pass
        drn_drn.DRN = DRN
        drn_pkg.drn = drn_drn
        sys.modules["mmaction.models.localizers.drn"] = drn_pkg
        sys.modules["mmaction.models.localizers.drn.drn"] = drn_drn
        print("âœ… mmaction drn ëª¨ë“ˆ íŒ¨ì¹˜ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ drn íŒ¨ì¹˜ ì‹¤íŒ¨: {e}")

patch_mmaction_drn()

import torch
import torch.nn as nn                          
import numpy as np                             
import cv2                                     
import pandas as pd
from flask import Flask, request, jsonify, Response
from flask_cors import CORS

from mmaction.apis import init_recognizer, inference_recognizer
from mmengine.config import Config

app = Flask(__name__)
CORS(app)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“‚ ê²½ë¡œ ë° ëª¨ë¸ ì„¤ì •
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
BASE_DIR = "/home/ubuntu/ai-muncheol/backend"

MODEL_META = {
    1: {"k": 5,  "out_key": "accident_place",              "prob_key": "probability", "map_key": "model1", "db_map": "place", "label": "ì¥ì†Œ"},
    2: {"k": 10, "out_key": "accident_place_feature_code", "prob_key": "probability", "map_key": "model2", "db_map": "type",  "label": "ì‚¬ê³ ìœ í˜•"},
    3: {"k": 10, "out_key": "vehicle_a_code",              "prob_key": "prob",        "map_key": "model3", "db_map": "action", "label": "ì°¨ëŸ‰A"},
    4: {"k": 10, "out_key": "vehicle_b_code",              "prob_key": "prob",        "map_key": "model4", "db_map": "action", "label": "ì°¨ëŸ‰B"},
}

GROUPS = {
    "ì€ì„": "es",
    "í˜•ì„ ": "hs"
}

MODELS_CONFIG = {}
for name_kr, prefix in GROUPS.items():
    for i in range(1, 5):
        key = f"{prefix}_model{i}"
        meta = MODEL_META[i]
        
        MODELS_CONFIG[key] = {
            "config": os.path.join(BASE_DIR, "configs", f"{key}_config.py"),
            "checkpoint": os.path.join(BASE_DIR, "weights", f"{key}.pth"),
            "meta": meta,
            "group": name_kr
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• C3D ëª¨ë¸ ì„¤ì •
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
C3D_CHECKPOINT = os.path.join(BASE_DIR, "weights", "best_c3d.pt")
C3D_RESIZE = 224       # í•™ìŠµ ì‹œ ì‚¬ìš©í•œ í•´ìƒë„ (ë…¸íŠ¸ë¶ Cell 35 í™•ì¸: RESIZE=224)
C3D_T = 16             # í´ë¦½ í”„ë ˆì„ ìˆ˜
C3D_NUM_CLASSES = 117  # í•™ìŠµ ì‹œ í´ë˜ìŠ¤ ìˆ˜


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• C3D ëª¨ë¸ í´ë˜ìŠ¤ (v9: AdaptivePool, 224Ã—224 ì…ë ¥)
#    - ë…¸íŠ¸ë¶ Cell 35 ì¶”ë¡  ì½”ë“œì—ì„œ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜´
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class C3D(nn.Module):
    """
    jfzhang95 C3D êµ¬ì¡° (Sports-1M pretrained í˜¸í™˜)
    í•™ìŠµ ì…ë ¥: (B, 3, 16, 224, 224) + AdaptiveAvgPool3d
    """
    def __init__(self, num_classes=117):
        super(C3D, self).__init__()
        self.conv1 = nn.Conv3d(3, 64, kernel_size=(3,3,3), padding=(1,1,1))
        self.pool1 = nn.MaxPool3d(kernel_size=(1,2,2), stride=(1,2,2))
        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3,3,3), padding=(1,1,1))
        self.pool2 = nn.MaxPool3d(kernel_size=(2,2,2), stride=(2,2,2))
        self.conv3a = nn.Conv3d(128, 256, kernel_size=(3,3,3), padding=(1,1,1))
        self.conv3b = nn.Conv3d(256, 256, kernel_size=(3,3,3), padding=(1,1,1))
        self.pool3 = nn.MaxPool3d(kernel_size=(2,2,2), stride=(2,2,2))
        self.conv4a = nn.Conv3d(256, 512, kernel_size=(3,3,3), padding=(1,1,1))
        self.conv4b = nn.Conv3d(512, 512, kernel_size=(3,3,3), padding=(1,1,1))
        self.pool4 = nn.MaxPool3d(kernel_size=(2,2,2), stride=(2,2,2))
        self.conv5a = nn.Conv3d(512, 512, kernel_size=(3,3,3), padding=(1,1,1))
        self.conv5b = nn.Conv3d(512, 512, kernel_size=(3,3,3), padding=(1,1,1))
        self.pool5 = nn.MaxPool3d(kernel_size=(2,2,2), stride=(2,2,2), padding=(0,1,1))
        self.adaptive_pool = nn.AdaptiveAvgPool3d((1, 4, 4))
        self.fc6 = nn.Linear(8192, 4096)
        self.fc7 = nn.Linear(4096, 4096)
        self.fc8 = nn.Linear(4096, num_classes)
        self.dropout = nn.Dropout(p=0.5)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.conv1(x)); x = self.pool1(x)
        x = self.relu(self.conv2(x)); x = self.pool2(x)
        x = self.relu(self.conv3a(x)); x = self.relu(self.conv3b(x)); x = self.pool3(x)
        x = self.relu(self.conv4a(x)); x = self.relu(self.conv4b(x)); x = self.pool4(x)
        x = self.relu(self.conv5a(x)); x = self.relu(self.conv5b(x)); x = self.pool5(x)
        x = self.adaptive_pool(x)
        x = x.view(-1, 8192)
        x = self.relu(self.fc6(x)); x = self.dropout(x)
        x = self.relu(self.fc7(x)); x = self.dropout(x)
        return self.fc8(x)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• C3D ì „ì²˜ë¦¬ í•¨ìˆ˜
#    - ë…¸íŠ¸ë¶ Cell 35ì˜ read_frames + sample_multi_clips(val) ì¬í˜„
#    - 224Ã—224 ë¦¬ì‚¬ì´ì¦ˆ â†’ 16í”„ë ˆì„ ì¤‘ì•™ í´ë¦½ â†’ BGRâ†’RGB â†’ /255 â†’ tensor
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def preprocess_video_for_c3d(video_path, T=16, resize=224):
    """
    C3D ì¶”ë¡ ìš© ì˜ìƒ ì „ì²˜ë¦¬ (í•™ìŠµ ë…¸íŠ¸ë¶ val ê²½ë¡œ ê·¸ëŒ€ë¡œ)

    Returns: (1, 3, T, resize, resize) float32 tensor
    """
    # 1) í”„ë ˆì„ ì½ê¸° + 224Ã—224 ë¦¬ì‚¬ì´ì¦ˆ
    cap = cv2.VideoCapture(video_path)
    frames = []
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.resize(frame, (resize, resize))
        frames.append(frame)
    cap.release()

    if len(frames) == 0:
        raise RuntimeError(f"No frames in {video_path}")

    # 2) loop pad (í”„ë ˆì„ < Tì¼ ë•Œ ë°˜ë³µ)
    if len(frames) < T:
        repeat = (T + len(frames) - 1) // len(frames)
        frames = (frames * repeat)

    # 3) ì¤‘ì•™ í´ë¦½ ìƒ˜í”Œë§ (val: num_clips=1, center)
    L = len(frames)
    start = max(0, (L - T) // 2)
    clip = frames[start:start + T]
    if len(clip) < T:
        clip = clip + [clip[-1]] * (T - len(clip))

    # 4) numpy â†’ tensor ë³€í™˜
    clip = np.stack(clip, axis=0)              # (T, 224, 224, 3) BGR
    clip = clip[..., ::-1].copy()               # BGR â†’ RGB
    clip = clip.astype(np.float32) / 255.0
    clip = np.transpose(clip, (3, 0, 1, 2))    # (3, T, 224, 224)

    # 5) ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    tensor = torch.from_numpy(clip).unsqueeze(0)  # (1, 3, T, 224, 224)
    return tensor


def run_c3d_inference(model, video_path, device, idx_to_class, k=10):
    """
    C3D ì¶”ë¡  ì‹¤í–‰ â†’ top-K ì˜ˆì¸¡ ë°˜í™˜

    Returns: list of {class_label: int, prob: float, model_idx: int}
    """
    tensor = preprocess_video_for_c3d(video_path, T=C3D_T, resize=C3D_RESIZE)
    tensor = tensor.to(device)

    with torch.no_grad():
        logits = model(tensor)                          # (1, num_classes)
        probs = torch.softmax(logits, dim=1).squeeze(0).cpu()

    topk_vals, topk_inds = torch.topk(probs, min(k, len(probs)))

    results = []
    for idx, prob in zip(topk_inds.tolist(), topk_vals.tolist()):
        class_label = idx_to_class.get(idx, idx)   # ëª¨ë¸ ì¸ë±ìŠ¤ â†’ ì›ë˜ í´ë˜ìŠ¤ ë¼ë²¨
        results.append({
            "class_label": int(class_label),
            "model_idx": idx,
            "prob": float(prob),
        })

    print(f"  ğŸ“Š [C3D] Top-5 ì˜ˆì¸¡:")
    for r in results[:5]:
        print(f"      í´ë˜ìŠ¤={r['class_label']}, prob={r['prob']:.4f}")

    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ—ºï¸ ëª¨ë¸ ì¸ë±ìŠ¤ â†’ DB ID ë§¤í•‘ (ê¸°ì¡´ ê·¸ëŒ€ë¡œ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MAP_MODEL1 = {i: v for i, v in enumerate([0, 1, 2, 3, 4, 5, 6, 13])}
MAP_MODEL2 = {i: v for i, v in enumerate([
    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 17, 18, 20, 21, 22, 23, 24,
    37, 38, 39, 40, 41, 45, 48, 49, 50, 59, 60
])}
MAP_MODEL3 = {i: v for i, v in enumerate([
    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20,
    21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 43, 44, 45,
    46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 88, 89,
    90, 91, 133, 134, 135, 138, 139, 140, 144, 147, 148, 154, 169, 170, 171,
    172, 173, 174, 175, 176, 177, 178, 179
])}
MAP_MODEL4 = {i: v for i, v in enumerate([
    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21,
    23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 45, 46, 47, 50,
    52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 74,
    87, 88, 89, 90, 91, 92, 139, 140, 142, 143, 146, 147, 150, 151, 165, 166,
    167, 168, 169, 170, 171, 172, 173
])}

MODEL_MAPS = {
    "model1": MAP_MODEL1,
    "model2": MAP_MODEL2,
    "model3": MAP_MODEL3,
    "model4": MAP_MODEL4,
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š ë¼ë²¨ ë§µ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
LABEL_MAP_PLACE = {
    0: "ì§ì„  ë„ë¡œ", 1: "ì‹ í˜¸ ì—†ëŠ” êµì°¨ë¡œ", 2: "ì‹ í˜¸ ìˆëŠ” êµì°¨ë¡œ",
    3: "tìí˜• ë„ë¡œ", 4: "ê¸°íƒ€ ë„ë¡œ", 5: "ì£¼ì°¨ì¥",
    6: "íšŒì „ êµì°¨ë¡œ", 13: "ê³ ì†ë„ë¡œ"
}

LABEL_MAP_TYPE = {}
LABEL_MAP_ACTION = {}
CRASH_DF = pd.DataFrame()

def load_csv_labels():
    global CRASH_DF, LABEL_MAP_TYPE, LABEL_MAP_ACTION

    csv_candidates = [
        os.path.join(BASE_DIR, "data", "matching.csv"),
    ]

    df = pd.DataFrame()
    final_path = None

    for p in csv_candidates:
        if not os.path.exists(p):
            continue
        for enc in ["utf-8-sig", "utf-8", "cp949", "euc-kr"]:
            try:
                temp = pd.read_csv(p, encoding=enc)
                temp.columns = temp.columns.str.strip()
                if "ê³¼ì‹¤ë¹„ìœ¨A" in temp.columns and "ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID" in temp.columns:
                    df = temp
                    final_path = p
                    break
            except Exception:
                continue
        if not df.empty:
            break

    if df.empty:
        print("âš ï¸ 'ê³¼ì‹¤ë¹„ìœ¨A' ì»¬ëŸ¼ì´ í¬í•¨ëœ ìœ íš¨í•œ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    for col in ["ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID", "Aì§„í–‰ë°©í–¥_ID", "Bì§„í–‰ë°©í–¥_ID"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(-1).astype(int)

    CRASH_DF = df

    if "ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID" in df.columns and "ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•" in df.columns:
        LABEL_MAP_TYPE = df.groupby("ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID")["ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•"].first().to_dict()
        LABEL_MAP_TYPE[45] = LABEL_MAP_TYPE.get(9, "ê¸°íƒ€ ì‚¬ê³ (48ë²ˆ ëŒ€ì²´)")

    if "Aì§„í–‰ë°©í–¥_ID" in df.columns:
        map_a = df[["Aì§„í–‰ë°©í–¥_ID", "Aì§„í–‰ë°©í–¥"]].dropna().drop_duplicates()
        map_b = df[["Bì§„í–‰ë°©í–¥_ID", "Bì§„í–‰ë°©í–¥"]].dropna().drop_duplicates()
        map_a.columns = ["ID", "Label"]
        map_b.columns = ["ID", "Label"]
        combined = pd.concat([map_a, map_b]).drop_duplicates(subset="ID")
        LABEL_MAP_ACTION = combined.set_index("ID")["Label"].to_dict()

    print(f"âœ… CSV ë¡œë“œ ì™„ë£Œ ({os.path.basename(final_path)}): {len(df)}í–‰, ì‚¬ê³ ìœ í˜• {len(LABEL_MAP_TYPE)}ê°œ, ì§„í–‰ë°©í–¥ {len(LABEL_MAP_ACTION)}ê°œ")

LABEL_MAPS = {
    "place": LABEL_MAP_PLACE,
    "type": LABEL_MAP_TYPE,
    "action": LABEL_MAP_ACTION,
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ Config ë¡œë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def safe_load_config(config_path):
    with open(config_path, "r", encoding="utf-8") as f:
        text = f.read()
    
    text = re.sub(r"custom_imports\s*=\s*dict\(.*?\)\s*\n", "", text, flags=re.DOTALL)
    
    if "LDAMLossCustom" in text:
        print(f" ğŸ› ï¸ [Config íŒ¨ì¹˜] {os.path.basename(config_path)}: LDAMLossCustom ì œê±° ì¤‘...")
        text = text.replace("'LDAMLossCustom'", "'CrossEntropyLoss'")
        text = text.replace('"LDAMLossCustom"', '"CrossEntropyLoss"')
        text = re.sub(r"cls_num_list\s*=\s*\[.*?\]\s*,?", "", text, flags=re.DOTALL)
        text = re.sub(r"\bmax_m\s*=\s*[\d\.]+\s*,?", "", text)
        text = re.sub(r"\bs\s*=\s*[\d\.]+\s*,?", "", text)
        
    text = re.sub(
        r"loss_cls=dict\(\s*alpha=[\s\S]*?type='mmdet\.FocalLoss'[\s\S]*?\)",
        "loss_cls=dict(type='CrossEntropyLoss', loss_weight=1.0)",
        text,
    )
    
    text = re.sub(r"load_from\s*=\s*'[^']*'", "load_from = None", text)

    with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False, encoding="utf-8") as tmp:
        tmp.write(text)
        tmp_path = tmp.name
    
    try:
        cfg = Config.fromfile(tmp_path)
    finally:
        if os.path.exists(tmp_path):
            os.remove(tmp_path)
            
    return cfg


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¬ ì˜ìƒ ì½”ë± í™•ì¸ / ë³€í™˜ (ffmpeg)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def get_video_codec(video_path):
    try:
        result = subprocess.run(
            ['ffprobe', '-v', 'error', '-select_streams', 'v:0',
             '-show_entries', 'stream=codec_name',
             '-of', 'default=noprint_wrappers=1:nokey=1', video_path],
            capture_output=True, text=True, timeout=10
        )
        return result.stdout.strip()
    except Exception:
        return "unknown"


def get_video_duration(video_path):
    try:
        result = subprocess.run(
            ['ffprobe', '-v', 'error', '-show_entries', 'format=duration',
             '-of', 'default=noprint_wrappers=1:nokey=1', video_path],
            capture_output=True, text=True, timeout=10
        )
        return float(result.stdout.strip())
    except Exception:
        return None


def convert_to_h264(input_path, output_path):
    try:
        command = [
            'ffmpeg', '-y', '-i', input_path,
            '-vcodec', 'libx264',
            '-preset', 'ultrafast',
            '-crf', '23',
            '-acodec', 'aac', '-strict', '-2',
            output_path
        ]
        subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, timeout=120)
        return True
    except Exception as e:
        print(f"  âš ï¸ H.264 ë³€í™˜ ì‹¤íŒ¨: {e}")
        return False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§  Top-K ì¶”ì¶œ (mmaction2 1.2.0 í˜¸í™˜)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def extract_top_k(res, model_name="", k=3):
    if isinstance(res, (list, tuple)):
        res = res[0]

    scores = None
    attrs = [a for a in dir(res) if not a.startswith('_')]

    if hasattr(res, 'pred_score') and scores is None:
        val = getattr(res, 'pred_score')
        if torch.is_tensor(val):
            scores = val

    if hasattr(res, 'pred_scores') and scores is None:
        pred_scores = getattr(res, 'pred_scores')
        if torch.is_tensor(pred_scores):
            scores = pred_scores
        else:
            if hasattr(pred_scores, 'keys'):
                try:
                    for key in pred_scores.keys():
                        val = pred_scores[key]
                        if torch.is_tensor(val):
                            scores = val
                            break
                except Exception:
                    pass
            if scores is None and hasattr(pred_scores, 'values'):
                try:
                    for val in pred_scores.values():
                        if torch.is_tensor(val):
                            scores = val
                            break
                except Exception:
                    pass
            for attr in ['data', 'score', 'scores', 'label']:
                if scores is not None:
                    break
                if hasattr(pred_scores, attr):
                    val = getattr(pred_scores, attr)
                    if torch.is_tensor(val):
                        scores = val

    if scores is None:
        for attr_name in attrs:
            if 'score' in attr_name.lower():
                val = getattr(res, attr_name, None)
                if torch.is_tensor(val) and val.dim() >= 1:
                    scores = val
                    break

    if scores is None:
        raise ValueError(f"[{model_name}] scores ì¶”ì¶œ ì‹¤íŒ¨!")

    if scores.dim() > 1:
        scores = scores.squeeze()
    scores = scores.cpu().to(torch.float64)

    print(f"  ğŸ“Š [{model_name}] scores shape: {scores.shape}")
    top5 = scores.topk(min(5, len(scores)))
    print(f"  ğŸ“Š [{model_name}] ìƒìœ„5 ê°’: {[f'{v:.4f}' for v in top5.values.tolist()]}")
    print(f"  ğŸ“Š [{model_name}] ìƒìœ„5 idx: {top5.indices.tolist()}")

    if scores.min() >= 0 and scores.max() <= 1 and scores.sum() > 0.5:
        probs = scores / scores.sum()
    else:
        probs = torch.nn.functional.softmax(scores, dim=0)

    topk_vals, topk_inds = torch.topk(probs, min(k, len(probs)))
    return topk_inds.tolist(), topk_vals.tolist()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âš–ï¸ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ (ì€ì„/í˜•ì„ ìš© - ê¸°ì¡´ ê·¸ëŒ€ë¡œ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def calculate_fault_scores(group_data, crash_df):
    """
    group_data: final_output["ì€ì„"] ë˜ëŠ” final_output["í˜•ì„ "] ë¦¬ìŠ¤íŠ¸
    """
    if crash_df.empty or len(group_data) < 4:
        return None, []

    cand_type = group_data[1] if group_data[1] else []
    cand_a = group_data[2] if group_data[2] else []
    cand_b = group_data[3] if group_data[3] else []

    eps = 1e-12
    combinations = []

    for t in cand_type:
        for a in cand_a:
            for b in cand_b:
                t_code = t.get("accident_place_feature_code")
                a_code = a.get("vehicle_a_code")
                b_code = b.get("vehicle_b_code", b.get("vehicle_b_info_code"))
                
                t_prob = t.get("probability", t.get("prob", 0))
                a_prob = a.get("probability", a.get("prob", 0))
                b_prob = b.get("probability", b.get("prob", 0))

                if t_code is None or a_code is None or b_code is None:
                    continue

                log_score = (
                    math.log(max(float(t_prob), eps))
                    + math.log(max(float(a_prob), eps))
                    + math.log(max(float(b_prob), eps))
                )
                combinations.append({
                    "type": t_code, "a": a_code, "b": b_code,
                    "log_score": log_score,
                })

    if not combinations:
        return None, []

    log_scores_tensor = torch.tensor([c["log_score"] for c in combinations], dtype=torch.float64)
    norm_confs = torch.nn.functional.softmax(log_scores_tensor, dim=0).tolist()

    for c, p in zip(combinations, norm_confs):
        c["norm_conf"] = p

    combinations.sort(key=lambda x: x["norm_conf"], reverse=True)

    fault_result = None
    alt_faults = []

    for combo in combinations:
        match_rows = crash_df[
            (crash_df["ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID"] == combo["type"])
            & (crash_df["Aì§„í–‰ë°©í–¥_ID"] == combo["a"])
            & (crash_df["Bì§„í–‰ë°©í–¥_ID"] == combo["b"])
        ]

        if not match_rows.empty:
            row = match_rows.iloc[0]
            fa = int(row["ê³¼ì‹¤ë¹„ìœ¨A"])
            fb = int(row["ê³¼ì‹¤ë¹„ìœ¨B"])

            entry = {
                "fa": fa,
                "fb": fb,
                "role_a": "ê°€í•´ì" if fa > fb else ("í”¼í•´ì" if fa < fb else "ìŒë°©"),
                "role_b": "í”¼í•´ì" if fa > fb else ("ê°€í•´ì" if fa < fb else "ìŒë°©"),
                "confidence": round(combo["norm_conf"] * 100, 2),
                "accident_place": str(row.get("ì‚¬ê³ ì¥ì†Œ", "")),
                "accident_feature": str(row.get("ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•", "")),
                "codes": f"T{combo['type']}-A{combo['a']}-B{combo['b']}"
            }

            if fault_result is None:
                fault_result = entry
            elif len(alt_faults) < 3:
                alt_faults.append(entry)

            if len(alt_faults) >= 3 and fault_result is not None:
                break

    return fault_result, alt_faults


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• C3D ê³¼ì‹¤ë¹„ìœ¨ ë§¤ì¹­ í•¨ìˆ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def calculate_c3d_fault(c3d_predictions, crash_df):
    """
    C3D ì˜ˆì¸¡ ê²°ê³¼ë¡œ ê³¼ì‹¤ë¹„ìœ¨ ë§¤ì¹­.
    
    C3DëŠ” traffic_accident_type(ì‚¬ê³ ìœ í˜• ID)ì„ ì§ì ‘ ì˜ˆì¸¡í•˜ë¯€ë¡œ
    crash_dfì—ì„œ í•´ë‹¹ ì‚¬ê³ ìœ í˜•ì˜ ëŒ€í‘œ í–‰ì„ ì°¾ì•„ ê³¼ì‹¤ë¹„ìœ¨ì„ ë°˜í™˜.
    
    ë§¤ì¹­ ì „ëµ (ìˆœì„œëŒ€ë¡œ ì‹œë„):
      1ìˆœìœ„: class_label â†’ crash_df í–‰ ì¸ë±ìŠ¤ë¡œ ì§ì ‘ ì¡°íšŒ
      2ìˆœìœ„: class_label â†’ ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID ì»¬ëŸ¼ì—ì„œ ê²€ìƒ‰
    """
    if crash_df.empty or not c3d_predictions:
        return None, []

    fault_result = None
    alt_faults = []

    for pred in c3d_predictions:
        label = pred["class_label"]
        prob = pred["prob"]
        row = None

        # ì „ëµ 1: class_labelì„ crash_df í–‰ ì¸ë±ìŠ¤ë¡œ ì‹œë„
        if 0 <= label < len(crash_df):
            row = crash_df.iloc[label]

        # ì „ëµ 2: ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID ì»¬ëŸ¼ì—ì„œ ê²€ìƒ‰
        if row is None:
            match = crash_df[crash_df["ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID"] == label]
            if not match.empty:
                row = match.iloc[0]

        if row is not None:
            fa = int(row["ê³¼ì‹¤ë¹„ìœ¨A"])
            fb = int(row["ê³¼ì‹¤ë¹„ìœ¨B"])
            entry = {
                "fa": fa,
                "fb": fb,
                "role_a": "ê°€í•´ì" if fa > fb else ("í”¼í•´ì" if fa < fb else "ìŒë°©"),
                "role_b": "í”¼í•´ì" if fa > fb else ("ê°€í•´ì" if fa < fb else "ìŒë°©"),
                "confidence": round(prob * 100, 2),
                "accident_place": str(row.get("ì‚¬ê³ ì¥ì†Œ", "")),
                "accident_feature": str(row.get("ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•", "")),
                "codes": f"C3D-class{label}"
            }

            if fault_result is None:
                fault_result = entry
            elif len(alt_faults) < 3:
                alt_faults.append(entry)

            if len(alt_faults) >= 3:
                break

    return fault_result, alt_faults


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• C3D ì˜ˆì¸¡ â†’ í”„ë¡ íŠ¸ì—”ë“œ 4-ëª¨ë¸ í˜•ì‹ ë³€í™˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def build_c3d_data(c3d_predictions, crash_df):
    """
    C3D ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í”„ë¡ íŠ¸ì—”ë“œê°€ ê¸°ëŒ€í•˜ëŠ” 4-ëª¨ë¸ ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜.
    
    í”„ë¡ íŠ¸ì—”ë“œ ê¸°ëŒ€ í˜•ì‹:
      c3d_data = [
        [{accident_place: code, probability: p}, ...],            # model1: ì¥ì†Œ
        [{accident_place_feature_code: code, probability: p}, ...], # model2: ì‚¬ê³ ìœ í˜•
        [{vehicle_a_code: code, prob: p}, ...],                   # model3: ì°¨ëŸ‰A
        [{vehicle_b_code: code, prob: p}, ...],                   # model4: ì°¨ëŸ‰B
      ]
    
    C3DëŠ” ì‚¬ê³ ìœ í˜•ì„ í†µì§¸ë¡œ ì˜ˆì¸¡í•˜ë¯€ë¡œ, crash_df í–‰ì—ì„œ ê°œë³„ ì½”ë“œë¥¼ ì¶”ì¶œ.
    """
    slot_place = []    # model1
    slot_type = []     # model2
    slot_a = []        # model3
    slot_b = []        # model4

    for pred in c3d_predictions[:10]:
        label = pred["class_label"]
        prob = pred["prob"]
        row = None

        # crash_dfì—ì„œ ë§¤ì¹­
        if 0 <= label < len(crash_df):
            row = crash_df.iloc[label]
        if row is None:
            match = crash_df[crash_df["ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID"] == label]
            if not match.empty:
                row = match.iloc[0]

        if row is not None:
            # ë§¤ì¹­ ì„±ê³µ â†’ crash_df í–‰ì—ì„œ ê°œë³„ ì½”ë“œ ì¶”ì¶œ
            if "ì‚¬ê³ ì¥ì†Œ_ID" in row.index:
                place_id = row["ì‚¬ê³ ì¥ì†Œ_ID"]
                if pd.notna(place_id):
                    slot_place.append({"accident_place": int(place_id), "probability": prob})

            type_id = row.get("ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID", -1)
            if pd.notna(type_id) and int(type_id) >= 0:
                slot_type.append({"accident_place_feature_code": int(type_id), "probability": prob})

            a_id = row.get("Aì§„í–‰ë°©í–¥_ID", -1)
            if pd.notna(a_id) and int(a_id) >= 0:
                slot_a.append({"vehicle_a_code": int(a_id), "prob": prob})

            b_id = row.get("Bì§„í–‰ë°©í–¥_ID", -1)
            if pd.notna(b_id) and int(b_id) >= 0:
                slot_b.append({"vehicle_b_code": int(b_id), "prob": prob})
        else:
            # ë§¤ì¹­ ì‹¤íŒ¨ â†’ class_labelì„ ì‚¬ê³ ìœ í˜• ì½”ë“œë¡œ ì§ì ‘ ì‚¬ìš©
            slot_type.append({"accident_place_feature_code": label, "probability": prob})

    return [slot_place, slot_type, slot_a, slot_b]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ ëª¨ë¸ ë¡œë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
loaded_models = {}
c3d_model = None                # ğŸ†•
c3d_idx_to_class = {}           # ğŸ†•
c3d_class_to_idx = {}           # ğŸ†•
VLM_SESSIONS = {}               # ğŸ†• ì„¸ì…˜ë³„ Gemini video_file + pred_codes ì €ì¥


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒ API ì—”ë“œí¬ì¸íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@app.route("/api/health", methods=["GET"])
def health():
    return jsonify({
        "status": "ok",
        "models_loaded": list(loaded_models.keys()),
        "c3d_loaded": c3d_model is not None,            # ğŸ†•
        "c3d_classes": len(c3d_idx_to_class),            # ğŸ†•
        "device": "cuda" if torch.cuda.is_available() else "cpu",
        "label_map_type_count": len(LABEL_MAPS.get("type", {})),
        "label_map_action_count": len(LABEL_MAPS.get("action", {})),
        "csv_rows": len(CRASH_DF),
    })


@app.route("/api/convert", methods=["POST"])
def convert_preview():
    """ë¸Œë¼ìš°ì € ë¯¸ë¦¬ë³´ê¸°ìš© H.264 ë³€í™˜"""
    if "video" not in request.files:
        return jsonify({"error": "ì˜ìƒ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤"}), 400

    video_file = request.files["video"]
    suffix = os.path.splitext(video_file.filename)[1] or ".mp4"
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
    video_file.save(tmp.name)
    tmp.close()
    input_path = tmp.name

    codec = get_video_codec(input_path)
    print(f"  ğŸ¬ [ë³€í™˜ ìš”ì²­] ì½”ë±: {codec}")

    if codec == "h264":
        from flask import send_file
        return send_file(input_path, mimetype="video/mp4", download_name="preview.mp4")

    output_path = input_path + "_h264.mp4"
    if convert_to_h264(input_path, output_path):
        os.remove(input_path)
        from flask import send_file
        resp = send_file(output_path, mimetype="video/mp4", download_name="preview.mp4")

        @resp.call_on_close
        def cleanup():
            try:
                os.remove(output_path)
            except Exception:
                pass

        return resp
    else:
        os.remove(input_path)
        return jsonify({"error": "ë³€í™˜ ì‹¤íŒ¨"}), 500


@app.route("/api/analyze", methods=["POST"])
def analyze():
    """8ê°œ mmaction ëª¨ë¸ + C3D ì‹¤í–‰ â†’ ê·¸ë£¹ë³„ ê²°ê³¼ + ê³¼ì‹¤ë¹„ìœ¨"""  # âœï¸
    if "video" not in request.files:
        return jsonify({"error": "ì˜ìƒ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤"}), 400

    video_file = request.files["video"]
    suffix = os.path.splitext(video_file.filename)[1] or ".mp4"
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
    video_file.save(tmp.name)
    tmp.close()
    video_path = tmp.name

    actual_video = video_path

    def generate():
        try:
            # â”€â”€â”€ 1. ê²°ê³¼ ê·¸ë¦‡ ì´ˆê¸°í™” â”€â”€â”€
            final_output = {
                "ì€ì„": [[], [], [], []],
                "í˜•ì„ ": [[], [], [], []]
            }

            # âœï¸ ì§„í–‰ë¥ : 8ê°œ mmaction + 1ê°œ C3D = ì´ 9ë‹¨ê³„
            total_models = len(MODELS_CONFIG)
            total_steps = total_models + (1 if c3d_model else 0)
            current_idx = 0

            # â”€â”€â”€ 2. mmaction ëª¨ë¸ 8ê°œ ìˆœíšŒ (ê¸°ì¡´ ê·¸ëŒ€ë¡œ) â”€â”€â”€
            sorted_keys = sorted(MODELS_CONFIG.keys())

            for key in sorted_keys:
                cfg = MODELS_CONFIG[key]
                group_name = cfg.get("group", "ì€ì„")

                model_num = int(key[-1])
                idx_in_group = model_num - 1

                meta = cfg.get("meta", cfg)
                k_val = meta.get("k", 10)
                out_key = meta.get("out_key", "code")
                prob_key = meta.get("prob_key", "prob")
                label_name = meta.get("label", f"ëª¨ë¸{model_num}")
                map_key = meta.get("map_key", f"model{model_num}")

                model = loaded_models.get(key)

                msg_text = f"{group_name} {label_name} ë¶„ì„ ì¤‘..."
                yield f"data: {json.dumps({'type': 'progress', 'message': msg_text, 'percent': int(current_idx / total_steps * 90)}, ensure_ascii=False)}\n\n"

                if not model:
                    print(f"âŒ {key} ëª¨ë¸ ë¯¸ë¡œë“œ")
                    current_idx += 1
                    continue

                res = inference_recognizer(model, actual_video)
                inds, probs = extract_top_k(res, model_name=key, k=k_val)

                mapping = MODEL_MAPS.get(map_key, {})

                model_result_list = []
                for idx, prob in zip(inds, probs):
                    code = mapping.get(idx, idx)
                    item = {
                        out_key: int(code),
                        prob_key: float(prob)
                    }
                    model_result_list.append(item)

                final_output[group_name][idx_in_group] = model_result_list
                current_idx += 1

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ğŸ†• 3. C3D ëª¨ë¸ ì¶”ë¡ 
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            c3d_data = None
            c3d_predictions = []

            if c3d_model is not None:
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ìˆ˜ë¯¼ 3D CNN ë¶„ì„ ì¤‘...', 'percent': int(current_idx / total_steps * 90)}, ensure_ascii=False)}\n\n"

                try:
                    device = next(c3d_model.parameters()).device
                    c3d_predictions = run_c3d_inference(
                        c3d_model, actual_video, device,
                        c3d_idx_to_class, k=10
                    )
                    c3d_data = build_c3d_data(c3d_predictions, CRASH_DF)
                    print(f"âœ… [C3D] ì¶”ë¡  ì™„ë£Œ: top1={c3d_predictions[0]['class_label']} "
                          f"(prob={c3d_predictions[0]['prob']:.4f})")
                except Exception as e:
                    print(f"âŒ [C3D] ì¶”ë¡  ì‹¤íŒ¨: {e}")
                    traceback.print_exc()

                current_idx += 1

            # â”€â”€â”€ 4. ê³¼ì‹¤ë¹„ìœ¨ ë§¤ì¹­ â”€â”€â”€
            fault_es, alt_es = calculate_fault_scores(final_output["ì€ì„"], CRASH_DF)
            fault_hs, alt_hs = calculate_fault_scores(final_output["í˜•ì„ "], CRASH_DF)
            fault_c3d, alt_c3d = calculate_c3d_fault(c3d_predictions, CRASH_DF)  # ğŸ†•

            if fault_es:
                print(f"âš–ï¸ [ì€ì„] ê³¼ì‹¤ë¹„ìœ¨: A={fault_es['fa']}% / B={fault_es['fb']}%")
            else:
                print("âš ï¸ [ì€ì„] ê³¼ì‹¤ë¹„ìœ¨ ë§¤ì¹­ ì‹¤íŒ¨")

            if fault_hs:
                print(f"âš–ï¸ [í˜•ì„ ] ê³¼ì‹¤ë¹„ìœ¨: A={fault_hs['fa']}% / B={fault_hs['fb']}%")
            else:
                print("âš ï¸ [í˜•ì„ ] ê³¼ì‹¤ë¹„ìœ¨ ë§¤ì¹­ ì‹¤íŒ¨")

            if fault_c3d:                                                         # ğŸ†•
                print(f"âš–ï¸ [C3D] ê³¼ì‹¤ë¹„ìœ¨: A={fault_c3d['fa']}% / B={fault_c3d['fb']}%")
            else:
                print("âš ï¸ [C3D] ê³¼ì‹¤ë¹„ìœ¨ ë§¤ì¹­ ì‹¤íŒ¨")

            
            # ... (ì•ë¶€ë¶„: ì€ì„/í˜•ì„ /C3D ê³¼ì‹¤ë¹„ìœ¨ print ì¶œë ¥ ì™„ë£Œ) ...

            sumin_result = {"accident_type": None}
            if c3d_predictions and len(c3d_predictions) > 0:
                try:
                    top_class = int(c3d_predictions[0].get('class_label', -1))
                    sumin_result = {"accident_type": top_class}
                except Exception:
                    sumin_result = {"accident_type": c3d_predictions[0].get('class_label')}
            final_output["ìˆ˜ë¯¼"] = sumin_result


            # ğŸŒŸ 1ì°¨ ì „ì†¡ (partial_complete): ëª¨ë¸ ë¶„ì„ 3ê°œê°€ ëë‚¬ìœ¼ë‹ˆ ë¨¼ì € 6í˜ì´ì§€ë¡œ ë„˜ê¹€!
            partial_evt = {
                "type": "partial_complete",
                "input_data": final_output,
                "c3d_data": c3d_data, # ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€
                "fault_results": {
                    "ì€ì„": {"best": fault_es, "alts": alt_es},
                    "í˜•ì„ ": {"best": fault_hs, "alts": alt_hs},
                    "c3d":  {"best": fault_c3d, "alts": alt_c3d},
                },
                "fault": fault_es,
                "alt_faults": alt_es,
                "label_maps": {
                    "place":  {str(k): v for k, v in LABEL_MAPS["place"].items()},
                    "type":   {str(k): v for k, v in LABEL_MAPS["type"].items()},
                    "action": {str(k): v for k, v in LABEL_MAPS["action"].items()},
                }
            }
            yield f"data: {json.dumps(partial_evt, ensure_ascii=False)}\n\n"


            # â”€â”€â”€ 4.5 VLM ìŠ¤ì½”ì–´ë§ (ë¦¬í¬íŠ¸ëŠ” ê°œë³„ ìš”ì²­ ì‹œ ìƒì„±) â”€â”€â”€
            print(f"\nğŸš€ [VLM] ë¹„ë””ì˜¤ ì „ì²˜ë¦¬ (Crop & Resize) ì‹œì‘...", flush=True)
            
            cropped_video_path = video_path.replace('.mp4', '_cropped.mp4')
            preprocess_success = crop_and_resize_video(actual_video, cropped_video_path)
            vlm_upload_path = cropped_video_path if preprocess_success else actual_video
            
            video_stem = "test_video"
            api_key = os.getenv("GOOGLE_API_KEY")
            genai.configure(api_key=api_key)
            
            print(f"  ğŸš€ [VLM] Gemini API ë¹„ë””ì˜¤ ì—…ë¡œë“œ ì‹œì‘...", flush=True)
            video_file = genai.upload_file(path=vlm_upload_path) 
            
            print("  â³ [VLM] êµ¬ê¸€ ì„œë²„ì—ì„œ ì˜ìƒ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘...", flush=True)
            while True:
                video_file = genai.get_file(video_file.name)
                state = video_file.state.name
                if state == "PROCESSING":
                    print(".", end="", flush=True)
                    time.sleep(2)
                elif state == "ACTIVE":
                    print("\n  âœ… [VLM] ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ! (ACTIVE í™•ì¸)", flush=True)
                    break
                else:
                    print(f"\n  âŒ [VLM] ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨! ìƒíƒœ: {state}", flush=True)
                    break
            
            if video_file.state.name == "ACTIVE":
                success, best_pred_code, _, model_results = vlm_code.run_score_test(video_stem, 0, video_file, final_output)

                if success:
                    es_pred, hs_pred, total_pred1, total_pred2, sm_pred, vlm_scores, vlm_sources = model_results

                    # ğŸ†• ê°œë³„ ëª¨ë¸(ì€ì„/í˜•ì„ /ìˆ˜ë¯¼) ì¤‘ì—ì„œë§Œ ìµœì  ëª¨ë¸ ì„ ì • (í†µí•© í‘œì‹œ X)
                    def _code_match_count(code_a, code_b):
                        """ë‘ ì˜ˆì¸¡ì½”ë“œì˜ 4ìë¦¬ ì¤‘ ì¼ì¹˜í•˜ëŠ” ê°œìˆ˜ ë°˜í™˜ (ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)"""
                        if not code_a or not code_b: return -1
                        nums_a = re.findall(r'\d+', str(code_a))
                        nums_b = re.findall(r'\d+', str(code_b))
                        if len(nums_a) < 4 or len(nums_b) < 4: return -1
                        return sum(1 for a, b in zip(nums_a[:4], nums_b[:4]) if a == b)

                    best_model_name = None
                    # 1ìˆœìœ„: ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ëª¨ë¸
                    if best_pred_code == es_pred: best_model_name = "ë¯¼ë‹¤ì •"
                    elif best_pred_code == hs_pred: best_model_name = "ì—„ë„ì‹"
                    elif best_pred_code == sm_pred: best_model_name = "ìœ¤ ìŠ¬"
                    else:
                        # 2ìˆœìœ„: ê°€ì¥ ìœ ì‚¬í•œ(ì½”ë“œ ì¼ì¹˜ ìˆ˜ ë§ì€) ëª¨ë¸ ì„ íƒ
                        candidates = [
                            ("ì€ì„", es_pred, _code_match_count(best_pred_code, es_pred)),
                            ("í˜•ì„ ", hs_pred, _code_match_count(best_pred_code, hs_pred)),
                            ("ìˆ˜ë¯¼", sm_pred, _code_match_count(best_pred_code, sm_pred)),
                        ]
                        candidates.sort(key=lambda x: x[2], reverse=True)
                        best_model_name = candidates[0][0]
                        print(f"  â„¹ï¸ [VLM] ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ëª¨ë¸ ì—†ìŒ â†’ ê°€ì¥ ìœ ì‚¬í•œ '{best_model_name}' ì„ íƒ "
                              f"(ì¼ì¹˜ {candidates[0][2]}/4)", flush=True)

                    print(f"  ğŸ† [VLM] 1ë“± ëª¨ë¸ ì„ ì •: {best_model_name}", flush=True)

                    # ğŸ†• ì„¸ì…˜ì— Gemini video_file + ì˜ˆì¸¡ì½”ë“œ ì €ì¥ (ê°œë³„ ë¦¬í¬íŠ¸ ìƒì„±ìš©)
                    session_id = str(uuid.uuid4())[:8]
                    pred_codes = {}
                    if es_pred and es_pred != "(-1, -1, -1, -1)":
                        pred_codes["ì€ì„"] = es_pred
                    if hs_pred and hs_pred != "(-1, -1, -1, -1)":
                        pred_codes["í˜•ì„ "] = hs_pred
                    if sm_pred and sm_pred != "(-1, -1, -1, -1)":
                        pred_codes["ìˆ˜ë¯¼"] = sm_pred

                    VLM_SESSIONS[session_id] = {
                        "video_file": video_file,
                        "pred_codes": pred_codes,
                        "video_stem": video_stem,
                        "created_at": time.time(),
                    }
                    print(f"  ğŸ’¾ [VLM] ì„¸ì…˜ ì €ì¥: {session_id}, ì˜ˆì¸¡ì½”ë“œ: {list(pred_codes.keys())}", flush=True)

                    # ğŸŒŸ vlm_ready ì´ë²¤íŠ¸: í”„ë¡ íŠ¸ì—ì„œ ê°œë³„ ë¦¬í¬íŠ¸ ìš”ì²­ ê°€ëŠ¥í•´ì§
                    vlm_ready_evt = {
                        "type": "vlm_ready",
                        "session_id": session_id,
                        "best_model": best_model_name,
                        "best_code": best_pred_code,
                        "pred_codes": pred_codes,
                    }
                    yield f"data: {json.dumps(vlm_ready_evt, ensure_ascii=False)}\n\n"
                else:
                    yield f"data: {json.dumps({'type': 'vlm_ready', 'session_id': None, 'error': 'VLM ìŠ¤ì½”ì–´ë§ ì‹¤íŒ¨'}, ensure_ascii=False)}\n\n"
            else:
                yield f"data: {json.dumps({'type': 'vlm_ready', 'session_id': None, 'error': f'Gemini ì˜ìƒ ì²˜ë¦¬ ì‹¤íŒ¨: {video_file.state.name}'}, ensure_ascii=False)}\n\n"

            # â”€â”€â”€ ì„ì‹œ íŒŒì¼ ì²­ì†Œ (ìë¥¸ ì˜ìƒ ì§€ì›€) â”€â”€â”€
            if os.path.exists(cropped_video_path):
                os.remove(cropped_video_path)

        except Exception as e:
            traceback.print_exc()
            yield f"data: {json.dumps({'type': 'error', 'error': str(e)}, ensure_ascii=False)}\n\n"
        finally:
            if os.path.exists(video_path):
                os.remove(video_path)

    return Response(generate(), mimetype="text/event-stream")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• ê°œë³„ VLM ë¦¬í¬íŠ¸ ìƒì„± ì—”ë“œí¬ì¸íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@app.route("/api/vlm_report", methods=["POST"])
def vlm_report():
    """ì„¸ì…˜ ID + ëª¨ë¸ ì´ë¦„ìœ¼ë¡œ ê°œë³„ VLM ë¦¬í¬íŠ¸ ìƒì„±"""
    data = request.get_json()
    session_id = data.get("session_id")
    model_name = data.get("model_name")  # "í˜•ì„ " / "ì€ì„" / "ìˆ˜ë¯¼"

    if not session_id or not model_name:
        return jsonify({"error": "session_idì™€ model_nameì´ í•„ìš”í•©ë‹ˆë‹¤"}), 400

    session = VLM_SESSIONS.get(session_id)
    if not session:
        return jsonify({"error": "ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆê±°ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"}), 404

    pred_code = session["pred_codes"].get(model_name)
    if not pred_code:
        return jsonify({"error": f"{model_name} ëª¨ë¸ì˜ ì˜ˆì¸¡ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤"}), 404

    video_file = session["video_file"]
    video_stem = session["video_stem"]

    try:
        print(f"  ğŸ“ [VLM] {model_name} ë¦¬í¬íŠ¸ ì‘ì„± ìš”ì²­ (session={session_id})...", flush=True)
        report_text = vlm_code.run_explan_test(video_stem, model_name, video_file, pred_code, "")

        if report_text:
            print(f"  âœ… [VLM] {model_name} ë¦¬í¬íŠ¸ ì‘ì„± ì™„ë£Œ!", flush=True)
            return jsonify({"status": "success", "report": report_text, "pred_code": pred_code})
        else:
            return jsonify({"status": "error", "message": f"{model_name} ë¦¬í¬íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."})
    except Exception as e:
        traceback.print_exc()
        return jsonify({"status": "error", "message": str(e)}), 500


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• VLM ì„¸ì…˜ ì •ë¦¬ (ì˜¤ë˜ëœ ì„¸ì…˜ ì‚­ì œ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@app.route("/api/vlm_cleanup", methods=["POST"])
def vlm_cleanup():
    """30ë¶„ ì´ìƒ ëœ ì„¸ì…˜ ìë™ ì •ë¦¬"""
    now = time.time()
    expired = [sid for sid, s in VLM_SESSIONS.items() if now - s["created_at"] > 1800]
    for sid in expired:
        try:
            VLM_SESSIONS[sid]["video_file"].delete()
        except Exception:
            pass
        del VLM_SESSIONS[sid]
    return jsonify({"cleaned": len(expired), "remaining": len(VLM_SESSIONS)})


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def load_all_models():
    global loaded_models, c3d_model, c3d_idx_to_class, c3d_class_to_idx
    device = "cuda:0" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {device}")

    # â”€â”€ mmaction ëª¨ë¸ 8ê°œ ë¡œë“œ (ê¸°ì¡´ ê·¸ëŒ€ë¡œ) â”€â”€
    sorted_keys = sorted(MODELS_CONFIG.keys())

    for key in sorted_keys:
        info = MODELS_CONFIG[key]
        config_path = info["config"]
        ckpt_path = info["checkpoint"]
        meta = info["meta"]

        if not os.path.exists(config_path):
            print(f"âŒ {key}: config ì—†ìŒ â†’ {config_path}")
            continue
        if not os.path.exists(ckpt_path):
            print(f"âŒ {key}: checkpoint ì—†ìŒ â†’ {ckpt_path}")
            continue

        try:
            print(f"ğŸ“¦ {key} ({meta['label']}) ë¡œë”© ì¤‘...")
            cfg = safe_load_config(config_path)

            if not hasattr(cfg, "test_pipeline") or cfg.test_pipeline is None:
                if hasattr(cfg, "val_pipeline"):
                    cfg.test_pipeline = cfg.val_pipeline

            model = init_recognizer(cfg, ckpt_path, device=device)
            loaded_models[key] = model
            print(f"âœ… {key} ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ {key} ë¡œë“œ ì‹¤íŒ¨: {e}")

    print(f"\nğŸ‰ ì´ {len(loaded_models)}/{len(MODELS_CONFIG)} mmaction ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ†• C3D ëª¨ë¸ ë¡œë“œ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if os.path.exists(C3D_CHECKPOINT):
        try:
            print(f"\nğŸ“¦ C3D ëª¨ë¸ ë¡œë”© ì¤‘... ({C3D_CHECKPOINT})")
            ckpt = torch.load(C3D_CHECKPOINT, map_location=device, weights_only=False)

            # ì²´í¬í¬ì¸íŠ¸ì—ì„œ í´ë˜ìŠ¤ ë§¤í•‘ ë³µì›
            c3d_class_to_idx = ckpt.get("class_to_idx", {})
            c3d_idx_to_class = ckpt.get("idx_to_class", {})
            num_classes = len(c3d_class_to_idx) if c3d_class_to_idx else C3D_NUM_CLASSES

            # ëª¨ë¸ ìƒì„± + ê°€ì¤‘ì¹˜ ë¡œë“œ
            c3d_model = C3D(num_classes=num_classes).to(device)
            c3d_model.load_state_dict(ckpt["model_state"])
            c3d_model.eval()

            epoch = ckpt.get("epoch", "?")
            val_acc = ckpt.get("best_val_acc", 0)
            print(f"âœ… C3D ë¡œë“œ ì™„ë£Œ: {num_classes}ê°œ í´ë˜ìŠ¤, "
                  f"epoch={epoch}, val_acc={val_acc * 100:.2f}%, "
                  f"ì…ë ¥=({C3D_T}Ã—{C3D_RESIZE}Ã—{C3D_RESIZE})")
        except Exception as e:
            print(f"âŒ C3D ë¡œë“œ ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            c3d_model = None
    else:
        print(f"\nâš ï¸ C3D ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ: {C3D_CHECKPOINT}")
        print("   â†’ C3D ì—†ì´ ì€ì„/í˜•ì„  ëª¨ë¸ë§Œìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ ì„œë²„ ì‹œì‘
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸš€ AI ë¬¸ì²  ë°±ì—”ë“œ ì„œë²„ v5 (SSE + C3D í†µí•©)")       # âœï¸ v4â†’v5
    print("=" * 60)
    load_csv_labels()
    LABEL_MAPS["type"] = LABEL_MAP_TYPE
    LABEL_MAPS["action"] = LABEL_MAP_ACTION
    load_all_models()
    print("\n" + "=" * 60)
    print("ğŸŒ ì„œë²„ ì‹¤í–‰: http://localhost:5002")
    if c3d_model:                                               # ğŸ†•
        print(f"ğŸ§¬ C3D ëª¨ë¸: í™œì„± ({len(c3d_idx_to_class)}ê°œ í´ë˜ìŠ¤)")
    else:
        print("ğŸ§¬ C3D ëª¨ë¸: ë¹„í™œì„± (ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ)")
    print("=" * 60 + "\n")
    app.run(host="0.0.0.0", port=5002, debug=False)