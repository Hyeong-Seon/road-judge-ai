import smtplib
from email.mime.text import MIMEText
import http.client
import json, re, os, random, csv, io, time
import pandas as pd
import google.generativeai as genai
from pathlib import Path
from google.generativeai import caching
import datetime
import itertools
import math
import ast

from dotenv import load_dotenv
load_dotenv('/home/ubuntu/ai-muncheol/backend/.env')

try:
    from google.colab import userdata
    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')
except ImportError:
    # Colab í™˜ê²½ì´ ì•„ë‹ ê²½ìš°(ë¡œì»¬ ë“±) í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì½ì–´ì˜¤ë„ë¡ ì„¤ì •
    GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# API ì„¤ì • ë° ëª¨ë¸ ì„ ì–¸ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY, transport='rest')
else:
    print("âš ï¸ ê²½ê³ : API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


#pdf_path = "/content/drive/MyDrive/cv_final/ë°ì´í„° ê´€ë ¨/1-56_êµí†µì‚¬ê³  ì˜ìƒ ë°ì´í„°_ê³¼ì‹¤ë¹„ìœ¨ ë‚´ìš© ì •ë¦¬.pdf"
#csv_gt_path = "/content/drive/MyDrive/cv_final/ë°ì´í„° ê´€ë ¨/ë¸”ë™ë°•ìŠ¤_ABì—¬ë¶€.csv" # ì—…ë¡œë“œí•˜ì‹  ì •ë‹µì§€ ê²½ë¡œ
mapping_path = "/home/ubuntu/ai-muncheol/backend/data/matching2.csv"
mapping_df = pd.read_csv(mapping_path, encoding='cp949')
csv_type_path='/home/ubuntu/ai-muncheol/backend/data/accident_type.csv'

#current_model_name = "gemini-3.1-pro-preview"
current_model_name = "gemini-3-flash-preview"

#base_video_root = "/content/cache/val/"
#base_label_root = "/content/cache/pred/"
#base_csv_root = "/content/cache/ana_log_final/"
#drive_root = "/content/drive/MyDrive/260220_ai"

place_hierarchy_instruction = """
[Place ê³„ì¸µ íŒë‹¨ ê·œì¹™]
- place ì½”ë“œë¥¼ ë°”ë¡œ ê³ ë¥´ì§€ ë§ê³ , ë¨¼ì € ë„ë¡œ í† í´ë¡œì§€(ëŒ€ë¶„ë¥˜)ë¥¼ íŒë‹¨í•˜ì‹­ì‹œì˜¤.
  1) ì§ì„  ë„ë¡œ ê³„ì—´: code 0
  2) ì‚¬ê±°ë¦¬ êµì°¨ë¡œ ê³„ì—´: code 1 ë˜ëŠ” 2
  3) Tìí˜• êµì°¨ë¡œ: code 3
  4) ì°¨ë„/ë¹„ì°¨ë„ ê²½ê³„ ë˜ëŠ” ë¹„ë„ë¡œ ê³„ì—´: code 4 ë˜ëŠ” 5
  5) íšŒì „êµì°¨ë¡œ: code 6
  6) ê³ ì†ë„ë¡œ/ìë™ì°¨ì „ìš©ë„ë¡œ ê³„ì—´: code 13

- ì´í›„ì—ë§Œ ì„¸ë¶€ place codeë¥¼ íŒë‹¨í•˜ì‹­ì‹œì˜¤.
  * ì‚¬ê±°ë¦¬ ê³„ì—´(1 vs 2): ì‹ í˜¸ë“± ìœ ë¬´ë¡œ êµ¬ë¶„
    - 1: ì‚¬ê±°ë¦¬êµì°¨ë¡œ(ì‹ í˜¸ë“± ì—†ìŒ)
    - 2: ì‚¬ê±°ë¦¬êµì°¨ë¡œ(ì‹ í˜¸ë“± ìˆìŒ)
  * ë¹„ë„ë¡œ ê³„ì—´(4 vs 5):
    - 5: ì£¼ì°¨ë©´/ì£¼ì°¨ë™ì„ /ì£¼ì°¨êµ¬íš ë‹¨ì„œê°€ ìˆìœ¼ë©´ ìš°ì„ 
    - 4: ì°¨ë„â†”ë¹„ì°¨ë„ ê²½ê³„/ë„ë¡œ ê°€ì¥ìë¦¬/ë¹„ë„ë¡œ ì§„ì… ê³„ì—´ì´ë©´ ìš°ì„ 
  * ì§ì„  vs ê³ ì†ë„ë¡œ(0 vs 13):
    - 13: ì¤‘ì•™ë¶„ë¦¬ëŒ€/ë‹¤ì°¨ë¡œ ê³ ì†ì£¼í–‰/ë¨í”„/ë°©ìŒë²½ ë“± ê³ ì†ë„ë¡œí˜• ì‹œì„¤ ë‹¨ì„œê°€ ìˆì„ ë•Œ ìš°ì„ 

- ëŒ€ë¶„ë¥˜ê°€ ëª…ë°±íˆ ë§ì§€ ì•ŠëŠ” ê°€ì„¤ì€ place_scoreë¥¼ ë‚®ê²Œ ì£¼ê³ , í•„ìš” ì‹œ hard_contradiction=trueë¡œ í‘œì‹œí•˜ì‹­ì‹œì˜¤.
"""

system_instruction_score_only = """
ë„ˆëŠ” êµí†µì‚¬ê³  ë¸”ë™ë°•ìŠ¤ ì˜ìƒì˜ í›„ë³´ ê°€ì„¤ë“¤ì„ 'ìµœì¢… ì„ íƒ'í•˜ì§€ ì•Šê³ , ì˜¤ì§ ì‹œê°ì  ì¼ì¹˜ë„ë§Œ ì±„ì í•˜ëŠ” í‰ê°€ê¸°ë‹¤.

[ëª©í‘œ]
- ê° í›„ë³´ ê°€ì„¤ì— ëŒ€í•´ place / feature / maneuver / role 4ê°œ ì¶•ì˜ ì‹œê° ì¼ì¹˜ë„ë¥¼ 0~4ì ìœ¼ë¡œ ì±„ì í•œë‹¤.
- ìµœì¢… 1ìœ„ ì„ íƒ, ìš°ìŠ¹ í›„ë³´ ê²°ì •, ê²°ë¡  ì„œì‚¬ ì‘ì„±ì€ í•˜ì§€ ì•ŠëŠ”ë‹¤.
- source_tag(Eunseok/Hyeongseon/Integrated ë“±)ì™€ section_typeì€ ì ìˆ˜ì— ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. (í›„ì²˜ë¦¬ì—ì„œë§Œ ì‚¬ìš©)

[í•µì‹¬ ê·œì¹™]
1) ìµœì¢… ì„ íƒ ê¸ˆì§€
- ì–´ë–¤ í›„ë³´ê°€ ì •ë‹µì¸ì§€ ê³ ë¥´ì§€ ë§ˆë¼.
- winner, top1, ìµœì¢…ì¶”ì²œ, ìµœì¢…íŒë‹¨, best hypothesis ê°™ì€ í‘œí˜„ì„ ì“°ì§€ ë§ˆë¼.
- final_decision_logic, why_not_runner_up ê°™ì€ ì„œì‚¬í˜• íŒë‹¨ì„ ë§Œë“¤ì§€ ë§ˆë¼.
- axis_comparisonì€ ì¶•ë³„ ë¹„êµ ë©”ëª¨ì¼ ë¿ ìµœì¢… ìŠ¹ìë¥¼ ì˜ë¯¸í•˜ì§€ ì•ŠëŠ”ë‹¤.

2) ë™ì  í—ˆìš©
- ë‘ í›„ë³´ê°€ ê°™ì€ ì¶•ì—ì„œ ëª¨ë‘ ë†’ì€ ì ìˆ˜(ì˜ˆ: ë‘˜ ë‹¤ 4ì )ì¼ ìˆ˜ ìˆë‹¤.
- ì–µì§€ë¡œ ì°¨ì´ë¥¼ ë§Œë“¤ì§€ ë§ˆë¼.
- ë³€ë³„ì´ ì–´ë ¤ìš´ ì¶•ì€ ë™ì /ë¶ˆí™•ì‹¤ë¡œ ë‚¨ê²¨ë¼.

3) ë°˜ì¦ ìš°ì„ 
- ê° í›„ë³´ì— ëŒ€í•´ score_reasonsë¿ ì•„ë‹ˆë¼ counter_evidenceë„ ë°˜ë“œì‹œ ê¸°ë¡í•œë‹¤.
- ë°˜ì¦ì´ ëª…í™•í•˜ë©´ ë†’ì€ ì ìˆ˜ë¥¼ ì£¼ì§€ ë§ˆë¼.
- ì ìˆ˜ëŠ” 'í›„ë³´ë¥¼ ë³€í˜¸'í•˜ì§€ ë§ê³ , ë³´ì´ëŠ” ë‹¨ì„œì™€ ë°˜ì¦ì„ í•¨ê»˜ ë°˜ì˜í•´ ì±„ì í•˜ë¼.

4) hard_contradiction ì‚¬ìš© ê¸°ì¤€ (ë§¤ìš° ë³´ìˆ˜ì )
- ì˜ìƒì—ì„œ ì§ì ‘ í™•ì¸ ê°€ëŠ¥í•œ ëª…ë°±í•œ ëª¨ìˆœì¼ ë•Œë§Œ hard_contradiction=trueë¡œ ë‘”ë‹¤.
- ì¶”ì •/ì• ë§¤í•¨/ê°€ë ¤ì§/í”„ë ˆì„ ë¶€ì¡±ì€ hard_contradiction=true ì‚¬ìœ ê°€ ì•„ë‹ˆë‹¤.
- hard_contradiction=true ì´ë©´ contradiction_axesì— í•´ë‹¹ ì¶•ëª…(place, feature, maneuver, role)ì„ ë„£ì–´ë¼.
- hard_contradiction=false ì´ë©´ contradiction_axesëŠ” ë¹ˆ ë°°ì—´ë¡œ ë‘˜ ìˆ˜ ìˆë‹¤.

5) source_tag / section_type ë¹„ì‚¬ìš©
- source_tag, section_typeì€ ë©”íƒ€ë°ì´í„°ë¡œë§Œ ê¸°ë¡í•œë‹¤.
- 'Eunseokì´ë¼ ë” ë†’ê²Œ', 'Hyeongseonì´ë¼ ë” ë‚®ê²Œ' ê°™ì€ prior íŒë‹¨ ê¸ˆì§€.

6) ì¶œë ¥ í˜•ì‹
- í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤.
- ì½”ë“œíœìŠ¤ ì—†ì´ JSON ê°ì²´ 1ê°œë§Œ ì¶œë ¥í•œë‹¤.
- JSON ì™¸ í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•˜ì§€ ë§ˆë¼.
- output_formatì— ì •ì˜ëœ í‚¤ ì´ë¦„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë¼.
- hypothesis_scoringì—ëŠ” ì…ë ¥ìœ¼ë¡œ ì œê³µëœ ëª¨ë“  í›„ë³´(H1, H2, H3)ë¥¼ ë¹ ì§ì—†ì´ í¬í•¨í•˜ë¼.

[ì ìˆ˜ ê¸°ì¤€: ëª¨ë“  ì¶• ê³µí†µ, 0~4 ì •ìˆ˜]
- 0: ëª…í™•í•œ ë¶ˆì¼ì¹˜/ëª¨ìˆœ (ì˜ìƒê³¼ ì§ì ‘ ì¶©ëŒ)
- 1: ì•½í•œ ì¼ì¹˜ ë˜ëŠ” ë‹¨ì„œ ë¶€ì¡± (ê·¼ê±°ê°€ ì•½í•¨)
- 2: ë¶€ë¶„ ì¼ì¹˜ (ë§ëŠ” ë¶€ë¶„ê³¼ ë¶ˆí™•ì‹¤/ì¶©ëŒ ìš”ì†Œê°€ í˜¼ì¬)
- 3: ê°•í•œ ì¼ì¹˜ (ì£¼ìš” ë‹¨ì„œë“¤ì´ ëŒ€ë¶€ë¶„ ì¼ì¹˜)
- 4: ë§¤ìš° ê°•í•œ ì¼ì¹˜ (ì§ì ‘ ì‹œê° ë‹¨ì„œê°€ ëª…í™•í•˜ê²Œ ë’·ë°›ì¹¨)

[ì¶•ë³„ í•´ì„ ê°€ì´ë“œ]
- place:
  êµì°¨ë¡œ/ì§ì„ /ë„ë¡œ êµ¬ì¡°/ì°¨ì„  íë¦„/ì •ì§€ì„ /ì‹ í˜¸ ìœ„ì¹˜ ë“± 'ì¥ì†Œ/í˜•íƒœ' ì¼ì¹˜ë„
- feature:
  ì¥ì†Œ ì„¸ë¶€ íŠ¹ì§•(í•©ë¥˜, ë¶„ê¸°, íš¡ë‹¨ë³´ë„, ì¤‘ì•™ì„  í˜•íƒœ, ì°¨ë¡œ ìˆ˜, ì°¨ë¡œ ë°°ì¹˜ ë“±) ì¼ì¹˜ë„
- maneuver:
  ì°¨ëŸ‰ë“¤ì˜ ì§„í–‰/íšŒì „/ì§„ì…/ì •ì§€/ì°¨ì„ ë³€ê²½/ìƒëŒ€ ì ‘ê·¼ ë°©í–¥/ì¶©ëŒ ì§ì „ ë™ì‘ ì¼ì¹˜ë„
- role:
  ë¸”ë™ë°•ìŠ¤ ì°¨ëŸ‰(ego)ê³¼ ìƒëŒ€ì°¨ëŸ‰(other)ì˜ ì—­í• /ë°©í–¥/ê´€ê³„, ê·¸ë¦¬ê³  A/B ë§¤í•‘ ì¼ì¹˜ë„

[ê°€ì‹œì„±/ê·¼ê±°ê°•ë„ í‘œê¸° ê·œì¹™]
- visibility ê°’ì€ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©:
  clear | partial | occluded | unknown
- basis ê°’ì€ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©:
  direct_visual | partial_visual | weak_inference | unknown

[ê´€ì°° ì‘ì„± ê°€ì´ë“œ]
- visual_observationì˜ ego_maneuver_guess / other_vehicle_maneuver_guessì—ëŠ” A/B ìš©ì–´ë¥¼ ì“°ì§€ ë§ê³  ego/other ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±í•˜ë¼.
- role_identificationì—ì„œë§Œ A/B ë§¤í•‘ì„ ë‹¤ë£¬ë‹¤.
- score_reasonsëŠ” ê° ì¶•ì˜ ì ìˆ˜ ë¶€ì—¬ ì´ìœ ë¥¼ ì§§ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ë¼.
- counter_evidenceëŠ” í•´ë‹¹ í›„ë³´ì— ë¶ˆë¦¬í•œ ë‹¨ì„œë¥¼ ê¸°ë¡í•˜ë¼. ì—†ìœ¼ë©´ None í˜•íƒœë¥¼ ì‚¬ìš©í•´ë„ ëœë‹¤.
- ê³¼ë„í•œ ì¥ë¬¸ ì„¤ëª… ëŒ€ì‹ , í”„ë ˆì„ ë‹¨ì„œ ì¤‘ì‹¬ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ë¼.

[axis_comparison ì‘ì„± ê·œì¹™]
- axis_comparisonì€ place/feature/maneuver/role ê° ì¶•ì˜ ë¹„êµ ë©”ëª¨ë‹¤.
- equal_groupsì—ëŠ” ë™ë¥ /ìœ ì‚¬í•œ í›„ë³´ ë¬¶ìŒì„ ê¸°ë¡í•œë‹¤. (ì˜ˆ: [["H1","H2"]])
- better_supportedì—ëŠ” í•´ë‹¹ ì¶•ì—ì„œ ê·¼ê±°ê°€ ìƒëŒ€ì ìœ¼ë¡œ ë” ì„ ëª…í•œ í›„ë³´ë¥¼ ê¸°ë¡í•  ìˆ˜ ìˆë‹¤.
- ì¶•ë³„ ë©”ëª¨(notes)ëŠ” ê°€ëŠ¥í•˜ë©´ ì§§ê²Œ ì‘ì„±í•œë‹¤.
- axis_comparisonìœ¼ë¡œ ì „ì²´ ìš°ìŠ¹ í›„ë³´ë¥¼ ë§Œë“¤ì§€ ë§ˆë¼.
"""

output_format_score_only = """
[output_format]
ì•„ë˜ í˜•ì‹ì˜ JSON ê°ì²´ 1ê°œë§Œ ì¶œë ¥í•˜ë¼.
- ì½”ë“œíœìŠ¤ ê¸ˆì§€
- JSON ì™¸ í…ìŠ¤íŠ¸ ê¸ˆì§€

{
  "meta": {
    "video_id": "ì…ë ¥ìœ¼ë¡œ ë°›ì€ video_id ë¬¸ìì—´ ê·¸ëŒ€ë¡œ",
    "section_type": "ì…ë ¥ìœ¼ë¡œ ë°›ì€ section_type ë¬¸ìì—´ ê·¸ëŒ€ë¡œ"
  },

  "pov_observation": {
    "camera_view": "ì „ë°©|í›„ë°©|ì¸¡ë©´|ë¶ˆëª…",
    "confidence": "low|med|high",
    "evidence": [
      {
        "time": "ì´ˆë°˜|ì¤‘ë°˜|ì¶©ëŒì§ì „|Xs",
        "detail": "ë¸”ë™ë°•ìŠ¤ ì‹œì (ì „ë°©/í›„ë°©/ì¸¡ë©´/ë¶ˆëª…) íŒë‹¨ ê·¼ê±°ë¥¼ ì§§ê²Œ"
      }
    ]
  },

  "visual_observation": {
    "road_topology_guess": "ì§ì„ ë„ë¡œê³„ì—´|ì‚¬ê±°ë¦¬ê³„ì—´|Tìí˜•|ë¹„ë„ë¡œê³„ì—´|íšŒì „êµì°¨ë¡œ|ê³ ì†ë„ë¡œê³„ì—´|ë¶ˆëª…",
    "ego_maneuver_guess": "ë¸”ë°•ì°¨(ego)ì˜ ë¬¼ë¦¬ì  ì›€ì§ì„ ìš”ì•½ (A/B ìš©ì–´ ê¸ˆì§€, ego/other ê¸°ì¤€)",
    "other_vehicle_maneuver_guess": "ìƒëŒ€ì°¨(other)ì˜ ë¬¼ë¦¬ì  ì›€ì§ì„ ìš”ì•½",
    "collision_geometry": "ì¶©ëŒ ìœ í˜•/ê°ë„/ë¶€ìœ„ ìš”ì•½ (ì˜ˆ: ì¸¡ë©´ ì ‘ì´‰, ì •ë©´ ì¶”ëŒ ê°€ëŠ¥ì„± ë“±)",
    "observation_confidence": "low|med|high",
    "environment_cues": [
      {
        "time": "ì´ˆë°˜|ì¤‘ë°˜|ì¶©ëŒì§ì „|Xs",
        "detail": "ë„ë¡œí˜•ìƒ/ì‹ í˜¸/ì°¨ì„ /ì •ì§€ì„ /ì¤‘ì•™ì„ /íš¡ë‹¨ë³´ë„/êµí†µíë¦„ ë‹¨ì„œ"
      }
    ]
  },

  "role_identification": {
    "blackbox_is": "A|B|unknown",
    "confidence": "low|med|high",
    "mapping_reason": "ego/other ê¸°ë™ ê´€ì°°ì„ ë°”íƒ•ìœ¼ë¡œ A/Bì— ë§¤í•‘í•œ ê·¼ê±°ë¥¼ 1~2ë¬¸ì¥ìœ¼ë¡œ",
    "evidence": [
      {
        "time": "ì´ˆë°˜|ì¤‘ë°˜|ì¶©ëŒì§ì „|Xs|None",
        "detail": "A/B ë§¤í•‘ ê·¼ê±° ë‹¨ì„œ (ì—†ìœ¼ë©´ None)"
      }
    ]
  },

  "hypothesis_scoring": [
    {
      "hypothesis_id": "H1",
      "target_code_combination": {
        "place": 0,
        "feature": 0,
        "vehicle_a": 0,
        "vehicle_b": 0
      },
      "target": "(P,F,A,B) ì¡°í•©ì˜ ì‚¬ëŒì´ ì½ëŠ” ì„¤ëª… í…ìŠ¤íŠ¸",
      "source_tag": "Agreement_Rank_1|Agreement_Rank_2|Agreement_Rank_3|Eunseok|Hyeongseon|Integrated|ê¸°íƒ€ì…ë ¥ê°’",

      "hard_contradiction": false,
      "contradiction_axes": ["place"],

      "scores": {
        "place_score": 0,
        "feature_score": 0,
        "maneuver_score": 0,
        "role_score": 0
      },

      "visibility": {
        "place": "clear|partial|occluded|unknown",
        "feature": "clear|partial|occluded|unknown",
        "maneuver": "clear|partial|occluded|unknown",
        "role": "clear|partial|occluded|unknown"
      },

      "basis": {
        "place": "direct_visual|partial_visual|weak_inference|unknown",
        "feature": "direct_visual|partial_visual|weak_inference|unknown",
        "maneuver": "direct_visual|partial_visual|weak_inference|unknown",
        "role": "direct_visual|partial_visual|weak_inference|unknown"
      },

      "score_reasons": {
        "place_reason": "ì¥ì†Œ/ë„ë¡œí˜•ìƒ ê´€ì°° ê¸°ì¤€ ì ìˆ˜ ë¶€ì—¬ ì´ìœ ",
        "feature_reason": "ì„¸ë¶€ íŠ¹ì§• ë‹¨ì„œ ê¸°ì¤€ ì ìˆ˜ ë¶€ì—¬ ì´ìœ ",
        "maneuver_reason": "ì§„í–‰/íšŒì „/ì¶©ëŒ ë™ì‘ ê¸°ì¤€ ì ìˆ˜ ë¶€ì—¬ ì´ìœ ",
        "role_reason": "A/B ì—­í•  ë§¤í•‘ ê¸°ì¤€ ì ìˆ˜ ë¶€ì—¬ ì´ìœ "
      },

      "counter_evidence": [
        {
          "time": "ì´ˆë°˜|ì¤‘ë°˜|ì¶©ëŒì§ì „|Xs|None",
          "type": "place|feature|maneuver|role|None",
          "detail": "ì´ í›„ë³´ì— ë¶ˆë¦¬í•œ ë°˜ì¦ ë‹¨ì„œ (ì—†ìœ¼ë©´ None)"
        }
      ]
    },

    {
      "hypothesis_id": "H2",
      "target_code_combination": {
        "place": 0,
        "feature": 0,
        "vehicle_a": 0,
        "vehicle_b": 0
      },
      "target": "(P,F,A,B) ì¡°í•©ì˜ ì‚¬ëŒì´ ì½ëŠ” ì„¤ëª… í…ìŠ¤íŠ¸",
      "source_tag": "Agreement_Rank_1|Agreement_Rank_2|Agreement_Rank_3|Eunseok|Hyeongseon|Integrated|ê¸°íƒ€ì…ë ¥ê°’",
      "hard_contradiction": false,
      "contradiction_axes": [],
      "scores": {
        "place_score": 0,
        "feature_score": 0,
        "maneuver_score": 0,
        "role_score": 0
      },
      "visibility": {
        "place": "clear|partial|occluded|unknown",
        "feature": "clear|partial|occluded|unknown",
        "maneuver": "clear|partial|occluded|unknown",
        "role": "clear|partial|occluded|unknown"
      },
      "basis": {
        "place": "direct_visual|partial_visual|weak_inference|unknown",
        "feature": "direct_visual|partial_visual|weak_inference|unknown",
        "maneuver": "direct_visual|partial_visual|weak_inference|unknown",
        "role": "direct_visual|partial_visual|weak_inference|unknown"
      },
      "score_reasons": {
        "place_reason": "ì¥ì†Œ/ë„ë¡œí˜•ìƒ ê´€ì°° ê¸°ì¤€ ì ìˆ˜ ë¶€ì—¬ ì´ìœ ",
        "feature_reason": "ì„¸ë¶€ íŠ¹ì§• ë‹¨ì„œ ê¸°ì¤€ ì ìˆ˜ ë¶€ì—¬ ì´ìœ ",
        "maneuver_reason": "ì§„í–‰/íšŒì „/ì¶©ëŒ ë™ì‘ ê¸°ì¤€ ì ìˆ˜ ë¶€ì—¬ ì´ìœ ",
        "role_reason": "A/B ì—­í•  ë§¤í•‘ ê¸°ì¤€ ì ìˆ˜ ë¶€ì—¬ ì´ìœ "
      },
      "counter_evidence": [
        {
          "time": "ì´ˆë°˜|ì¤‘ë°˜|ì¶©ëŒì§ì „|Xs|None",
          "type": "place|feature|maneuver|role|None",
          "detail": "ì´ í›„ë³´ì— ë¶ˆë¦¬í•œ ë°˜ì¦ ë‹¨ì„œ (ì—†ìœ¼ë©´ None)"
        }
      ]
    },

    {
      "hypothesis_id": "H3",
      "target_code_combination": {
        "place": 0,
        "feature": 0,
        "vehicle_a": 0,
        "vehicle_b": 0
      },
      "target": "(P,F,A,B) ì¡°í•©ì˜ ì‚¬ëŒì´ ì½ëŠ” ì„¤ëª… í…ìŠ¤íŠ¸",
      "source_tag": "Agreement_Rank_1|Agreement_Rank_2|Agreement_Rank_3|Eunseok|Hyeongseon|Integrated|ê¸°íƒ€ì…ë ¥ê°’",
      "hard_contradiction": false,
      "contradiction_axes": [],
      "scores": {
        "place_score": 0,
        "feature_score": 0,
        "maneuver_score": 0,
        "role_score": 0
      },
      "visibility": {
        "place": "clear|partial|occluded|unknown",
        "feature": "clear|partial|occluded|unknown",
        "maneuver": "clear|partial|occluded|unknown",
        "role": "clear|partial|occluded|unknown"
      },
      "basis": {
        "place": "direct_visual|partial_visual|weak_inference|unknown",
        "feature": "direct_visual|partial_visual|weak_inference|unknown",
        "maneuver": "direct_visual|partial_visual|weak_inference|unknown",
        "role": "direct_visual|partial_visual|weak_inference|unknown"
      },
      "score_reasons": {
        "place_reason": "ì¥ì†Œ/ë„ë¡œí˜•ìƒ ê´€ì°° ê¸°ì¤€ ì ìˆ˜ ë¶€ì—¬ ì´ìœ ",
        "feature_reason": "ì„¸ë¶€ íŠ¹ì§• ë‹¨ì„œ ê¸°ì¤€ ì ìˆ˜ ë¶€ì—¬ ì´ìœ ",
        "maneuver_reason": "ì§„í–‰/íšŒì „/ì¶©ëŒ ë™ì‘ ê¸°ì¤€ ì ìˆ˜ ë¶€ì—¬ ì´ìœ ",
        "role_reason": "A/B ì—­í•  ë§¤í•‘ ê¸°ì¤€ ì ìˆ˜ ë¶€ì—¬ ì´ìœ "
      },
      "counter_evidence": [
        {
          "time": "ì´ˆë°˜|ì¤‘ë°˜|ì¶©ëŒì§ì „|Xs|None",
          "type": "place|feature|maneuver|role|None",
          "detail": "ì´ í›„ë³´ì— ë¶ˆë¦¬í•œ ë°˜ì¦ ë‹¨ì„œ (ì—†ìœ¼ë©´ None)"
        }
      ]
    }
  ],

  "axis_comparison": {
    "place": {
      "equal_groups": [["H1","H2"]],
      "better_supported": ["H3"],
      "notes": ["ì¥ì†Œ ì¶• ë¹„êµ ë©”ëª¨ (ìµœì¢… ìŠ¹ì ì˜ë¯¸ ì•„ë‹˜)"]
    },
    "feature": {
      "equal_groups": [],
      "better_supported": [],
      "notes": ["ì„¸ë¶€íŠ¹ì§• ì¶• ë¹„êµ ë©”ëª¨ (ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ ê°€ëŠ¥)"]
    },
    "maneuver": {
      "equal_groups": [],
      "better_supported": [],
      "notes": ["ê¸°ë™ ì¶• ë¹„êµ ë©”ëª¨ (ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ ê°€ëŠ¥)"]
    },
    "role": {
      "equal_groups": [],
      "better_supported": [],
      "notes": ["ì—­í•  ì¶• ë¹„êµ ë©”ëª¨ (ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ ê°€ëŠ¥)"]
    }
  }
}
"""

system_instruction_explanation_direct = """
ë„ˆëŠ” êµí†µì‚¬ê³  ë¸”ë™ë°•ìŠ¤ ì˜ìƒì— ëŒ€í•´ 'ì´ë¯¸ í™•ì •ëœ ì‚¬ê³ ìœ í˜•'ì„ ì„¤ëª…í•˜ëŠ” ì‘ì„±ìë‹¤.

ì—­í• :
- ì…ë ¥ìœ¼ë¡œ ì£¼ì–´ì§„ í™•ì • ìœ í˜•(ì¥ì†Œ/íŠ¹ì§•/A ì°¨ëŸ‰ ê¸°ë™/B ì°¨ëŸ‰ ê¸°ë™/ê³¼ì‹¤ë¹„ìœ¨)ì„ ë°”íƒ•ìœ¼ë¡œ,
  ì˜ìƒì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì½ê¸° ì‰¬ìš´ ì„¤ëª…ì„ ì‘ì„±í•œë‹¤.
- ìµœì¢… ìœ í˜•ì„ ë‹¤ì‹œ ê³ ë¥´ê±°ë‚˜ ë°”ê¾¸ì§€ ì•ŠëŠ”ë‹¤.
- ì ìˆ˜ ì¬ê³„ì‚°, í›„ë³´ ë¹„êµ, ì¬ì„ íƒì„ í•˜ì§€ ì•ŠëŠ”ë‹¤.

ì¤‘ìš” ê·œì¹™:
1) ì„ íƒ ë³€ê²½ ê¸ˆì§€
- ì…ë ¥ìœ¼ë¡œ ì£¼ì–´ì§„ í™•ì • ìœ í˜•ì´ ìµœì¢… ê²°ê³¼ë‹¤.
- ë‹¤ë¥¸ ìœ í˜•ì´ ë” ë§ì•„ ë³´ì¸ë‹¤ëŠ” ì‹ì˜ ì¬íŒë‹¨ ê¸ˆì§€.
- í›„ë³´ ë¹„êµ/ìš°ìŠ¹ í›„ë³´/ì¬ë­í¬ ê¸ˆì§€.

2) A/B ì¤‘ë¦½ ì„œìˆ  ìœ ì§€ (ë§¤ìš° ì¤‘ìš”)
- 'ë‚´ ì°¨ëŸ‰', 'ë¸”ë°• ì°¨ëŸ‰', 'ìƒëŒ€ ì°¨ëŸ‰', 'ê°€í•´ì°¨ëŸ‰', 'í”¼í•´ì°¨ëŸ‰' ê°™ì€ í‘œí˜„ ê¸ˆì§€.
- ë°˜ë“œì‹œ 'A ì°¨ëŸ‰', 'B ì°¨ëŸ‰'ìœ¼ë¡œë§Œ ì„œìˆ í•œë‹¤.
- ì˜ìƒì—ì„œ ì¹´ë©”ë¼ ì‹œì ìœ¼ë¡œ A/Bë¥¼ ìƒˆë¡œ ì¶”ì •í•˜ë ¤ê³  í•˜ì§€ ë§ˆë¼.
- A/Bì˜ ì˜ë¯¸ëŠ” ì…ë ¥ëœ í™•ì • ìœ í˜• ì •ì˜ë¥¼ ê·¸ëŒ€ë¡œ ë”°ë¥¸ë‹¤.

3) ì˜ìƒ ê´€ì°°ì€ 'ë³´ê°• ì„¤ëª…'ìœ¼ë¡œë§Œ ì‚¬ìš©
- ì˜ìƒì€ í™•ì • ìœ í˜• ì„¤ëª…ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§Œë“œëŠ” ìš©ë„ë¡œë§Œ ì‚¬ìš©í•œë‹¤.
- ì˜ìƒì—ì„œ í™•ì‹¤í•˜ì§€ ì•Šì€ ë‚´ìš©ì€ ë‹¨ì •í•˜ì§€ ë§ê³  'í™•ì¸ ì–´ë ¤ì›€'ìœ¼ë¡œ ì“´ë‹¤.
- í™”ì§ˆ/ê°€ë¦¼/ì•¼ê°„/ì›ê±°ë¦¬ ë“±ì˜ ìƒí™©ì´ë¼ë©´ ë¶ˆí™•ì‹¤ì„±ì„ ëª…ì‹œí•œë‹¤.

4) ì„œìˆ ì˜ ì–´ì¡°ëŠ” ì¼ê´€ì ìœ¼ë¡œ ìœ ì§€
- ì‹œì‘ê³¼ ë ë¬¸êµ¬ë¥¼ í¬í•¨í•œ ì „ì²´ì ì¸ ì„œìˆ  í†¤ì€ ìœ ì € í”„ë¡¬í”„íŠ¸ì˜ [ì–´ì¡° ë° í…œí”Œë¦¿ ì§€ì¹¨]ì„ ìµœìš°ì„ ìœ¼ë¡œ ë”°ë¥¸ë‹¤.

5) ì¶œë ¥ í˜•ì‹
- ì½”ë“œíœìŠ¤ ì—†ì´ JSON ê°ì²´ 1ê°œë§Œ ì¶œë ¥í•œë‹¤.
- output_formatì— ì •ì˜ëœ í‚¤ ì´ë¦„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•œë‹¤.
- 'explanation_text' ì‘ì„± ì‹œ, ì œê³µëœ í…œí”Œë¦¿ì˜ {{ }} ìë¦¬ì— ì…ë ¥ ë°ì´í„°(ë‚ ì”¨, ì‹œê°„, ê¸°ë™, ë¹„ìœ¨ ë“±)ë¥¼ ì •í™•íˆ ë§¤í•‘í•˜ì—¬ ì¹˜í™˜í•œë‹¤.
- í…œí”Œë¦¿ì˜ ë³€ìˆ˜ ê°’ì„ ì„ì˜ë¡œ ë³€ê²½í•˜ê±°ë‚˜ ëˆ„ë½í•˜ì§€ ì•ŠëŠ”ë‹¤.
"""

output_format_explanation_direct = """
{
  "video_observation": {
    "scene_condition": {
      "time_of_day": "ì£¼ê°„|ì•¼ê°„|ë¶ˆëª…",
      "weather": "ë§‘ìŒ|ìš°ì²œ|íë¦¼|ë¶ˆëª…",
      "visibility_note": "í™”ì§ˆ/ê±°ë¦¬/ê°€ë¦¼/ì—­ê´‘ ë“± ê´€ì°° í’ˆì§ˆ ë©”ëª¨ (ì—†ìœ¼ë©´ 'ì—†ìŒ')"
    },
    "road_context": {
      "intersection_type_observed": "ì‚¬ê±°ë¦¬|Tìí˜•|ì§ì„ ë„ë¡œ|ê¸°íƒ€|ë¶ˆëª…",
      "signal_observed": "ì‹ í˜¸ë“± ìˆìŒ|ì‹ í˜¸ë“± ì—†ìŒ|í™•ì¸ ì–´ë ¤ì›€",
      "road_scale_hint": "ëŒ€ë¡œ/ì†Œë¡œ ë‹¨ì„œ ìˆìŒ|ë‹¨ì„œ ì•½í•¨|í™•ì¸ ì–´ë ¤ì›€",
      "lane_or_stopline_hint": "ì°¨ì„ /ì •ì§€ì„ /íš¡ë‹¨ë³´ë„ ë“± ë³´ì´ëŠ” ë‹¨ì„œ ìš”ì•½ (ì—†ìœ¼ë©´ 'í™•ì¸ ì–´ë ¤ì›€')"
    },
    "movement_observation": {
      "a_vehicle_observation": "ì…ë ¥ëœ A ì°¨ëŸ‰ ê¸°ë™ê³¼ ì¶©ëŒí•˜ì§€ ì•Šë„ë¡, ì˜ìƒì—ì„œ ë³´ì´ëŠ” ì›€ì§ì„ ë‹¨ì„œë¥¼ A ì°¨ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ ìš”ì•½",
      "b_vehicle_observation": "ì…ë ¥ëœ B ì°¨ëŸ‰ ê¸°ë™ê³¼ ì¶©ëŒí•˜ì§€ ì•Šë„ë¡, ì˜ìƒì—ì„œ ë³´ì´ëŠ” ì›€ì§ì„ ë‹¨ì„œë¥¼ B ì°¨ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ ìš”ì•½",
      "collision_moment": "ì¶©ëŒ ì‹œì /ìœ„ì¹˜/ê°ë„/ì ‘ì´‰ ì–‘ìƒ ìš”ì•½ (í™•ì¸ ì–´ë ¤ìš°ë©´ ê·¸ë ‡ê²Œ ëª…ì‹œ)"
    },
    "uncertainties": [
      "ë¶ˆí™•ì‹¤í•œ ì  1 (ì—†ìœ¼ë©´ 'ì—†ìŒ')"
    ]
  },
  "explanation_text": "ë°˜ë“œì‹œ ì§€ì •ëœ ì‹œì‘ ë¬¸êµ¬ë¡œ ì‹œì‘í•˜ê³ , ì§€ì •ëœ ë§ˆì¹¨ ë¬¸êµ¬ë¡œ ëë‚˜ëŠ” ì „ì²´ ì„¤ëª… ë¬¸ë‹¨. ì¤‘ê°„ì—ëŠ” ì‚¬ê³  ì •í™©ì„ ìƒì„¸íˆ í¬í•¨í•  ê²ƒ."
}
"""

## VLMìš© í•¨ìˆ˜ ëª¨ìŒ

# ==========================================
# 1. ê³ ì • ì„¤ì • (ìƒìˆ˜)
# ==========================================
SCORE_MODE = 'log'
EUNSEOK_WEIGHT = 1.0
HYUNGSUN_WEIGHT = 1.0
MODEL_WEIGHTS = [1.2, 1.0, 1.0, 0.8]
EPSILON = 1e-9

MODEL_MAP = {
    'model1_place': {'attr': 'accident_place', 'e_id': 'accident_place', 'e_prob': 'probability', 'h_id': 'accident_place', 'h_prob': 'probability'},
    'model2_feature': {'attr': 'accident_place_feature', 'e_id': 'accident_place_feature_code', 'e_prob': 'probability', 'h_id': 'accident_place_feature_code', 'h_prob': 'probability'},
    'model3_vehicle_a': {'attr': 'vehicle_a_progress_info', 'e_id': 'vehicle_a_code', 'e_prob': 'prob', 'h_id': 'vehicle_a_code', 'h_prob': 'prob'},
    'model4_vehicle_b': {'attr': 'vehicle_b_progress_info', 'e_id': 'vehicle_b_code', 'e_prob': 'prob', 'h_id': 'vehicle_b_info_code', 'h_prob': 'probability'}
}
TARGET_ATTRIBUTES = ['accident_place', 'accident_place_feature', 'vehicle_a_progress_info', 'vehicle_b_progress_info']

# ìœ íš¨ ì¡°í•© ë¡œë“œ (ì „ì—­ 1íšŒ ì‹¤í–‰)
VALID_COMBINATIONS = None
if os.path.exists(csv_type_path):
    df_valid = pd.read_csv(csv_type_path)
    VALID_COMBINATIONS = set(zip(df_valid['accident_place'], df_valid['accident_place_feature'], 
                                 df_valid['vehicle_a_progress_info'], df_valid['vehicle_b_progress_info']))

def get_all_predictions_simple(input_data):
    """
    input_dataë¥¼ ë°›ì•„ (ì€ì„_1ìœ„, í˜•ì„ _1ìœ„, í†µí•©_1ìœ„, í†µí•©_2ìœ„)ë¥¼ ë¦¬í„´í•©ë‹ˆë‹¤.
    """
    try:
        # 1. ë°ì´í„° êµ¬ì¡°í™”
        model_data = {attr: {'probs': {'ì€ì„': {}, 'í˜•ì„ ': {}}} for attr in TARGET_ATTRIBUTES}
        model_keys = ['model1_place', 'model2_feature', 'model3_vehicle_a', 'model4_vehicle_b']
        
        for person in ["ì€ì„", "í˜•ì„ "]:
            person_data = input_data.get(person, [])
            for i, model_results in enumerate(person_data):
                m_key = model_keys[i]
                m_info = MODEL_MAP[m_key]
                attr = m_info['attr']
                id_key = m_info['e_id'] if person == "ì€ì„" else m_info['h_id']
                prob_key = m_info['e_prob'] if person == "ì€ì„" else m_info['h_prob']
                
                for item in model_results:
                    code = item.get(id_key)
                    prob = item.get(prob_key, 0)
                    model_data[attr]['probs'][person][code] = prob

        # 2. ì¡°í•© ë° ì ìˆ˜ ê³„ì‚°
        c_lists = [list(set(model_data[a]['probs']['ì€ì„'].keys()) | set(model_data[a]['probs']['í˜•ì„ '].keys())) for a in TARGET_ATTRIBUTES]
        
        best_e = {"comb": None, "score": -float('inf')}
        best_h = {"comb": None, "score": -float('inf')}
        
        # í†µí•© ì ìˆ˜ ë­í‚¹ì„ ìœ„í•´ ëª¨ë“  ì¡°í•©ì˜ ì ìˆ˜ë¥¼ ì €ì¥
        total_scores = []

        for comb in itertools.product(*c_lists):
            if VALID_COMBINATIONS is not None and comb not in VALID_COMBINATIONS:
                continue

            # Log Score ê³„ì‚°
            raw_e = sum(MODEL_WEIGHTS[i] * math.log(model_data[TARGET_ATTRIBUTES[i]]['probs']['ì€ì„'].get(comb[i], 0) + EPSILON) for i in range(4))
            raw_h = sum(MODEL_WEIGHTS[i] * math.log(model_data[TARGET_ATTRIBUTES[i]]['probs']['í˜•ì„ '].get(comb[i], 0) + EPSILON) for i in range(4))
            
            # ê°€ì¤‘ì¹˜ ë°˜ì˜ (1:1 ë¹„ìœ¨)
            weighted_e = raw_e * EUNSEOK_WEIGHT
            weighted_h = raw_h * HYUNGSUN_WEIGHT
            integrated = weighted_e + weighted_h

            # ê°œë³„ ëª¨ë¸ 1ìœ„ ì¶”ì 
            if weighted_e > best_e["score"]: 
                best_e["score"], best_e["comb"] = weighted_e, comb
            if weighted_h > best_h["score"]: 
                best_h["score"], best_h["comb"] = weighted_h, comb
            
            # í†µí•© ì ìˆ˜ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
            total_scores.append({"comb": comb, "score": integrated})

        # í†µí•© ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        total_scores.sort(key=lambda x: x['score'], reverse=True)

        def f(c): return f"({c[0]}, {c[1]}, {c[2]}, {c[3]})" if c else "(-1, -1, -1, -1)"
        
        # ê²°ê³¼ ì¶”ì¶œ
        e_pred = f(best_e["comb"])
        h_pred = f(best_h["comb"])
        total_pred1 = f(total_scores[0]["comb"]) if len(total_scores) > 0 else "(-1, -1, -1, -1)"
        total_pred2 = f(total_scores[1]["comb"]) if len(total_scores) > 1 else "(-1, -1, -1, -1)"

        return e_pred, h_pred, total_pred1, total_pred2

    except Exception as e:
        print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return ("(-1, -1, -1, -1)", "(-1, -1, -1, -1)", "(-1, -1, -1, -1)", "(-1, -1, -1, -1)")


# ì¶œë ¥ ìƒì„±ìš© í—¬í¼ í•¨ìˆ˜ë“¤
# ==============================
# Short analysis row helpers
# ==============================
CONF_MAP = {"low": 1, "med": 2, "high": 3}
CAM_VIEW_MAP = {"ì „ë°©": 1, "í›„ë°©": 2, "ì¸¡ë©´": 3, "ë¶ˆëª…": 0}
ROAD_TOPO_MAP = {
    "ë¶ˆëª…": 0,
    "ì§ì„ ë„ë¡œê³„ì—´": 1,
    "ì‚¬ê±°ë¦¬ê³„ì—´": 2,
    "Tìí˜•": 3,
    "ë¹„ë„ë¡œê³„ì—´": 4,
    "íšŒì „êµì°¨ë¡œ": 5,
    "ê³ ì†ë„ë¡œê³„ì—´": 6,
}
VIS_MAP = {"unknown": 0, "occluded": 1, "partial": 2, "clear": 3}
BASIS_MAP = {"unknown": 0, "weak_inference": 1, "partial_visual": 2, "direct_visual": 3}

# source_tagë¥¼ ìˆ«ìë¡œ ì¸ì½”ë”© (í•„ìš” ì‹œ ì¶”ê°€)
SRC_MAP = {
    "": 0,
    "Eunseok": 1,
    "Hyeongseon": 2,
    "Integrated": 3,
    "Agreement_Rank_1": 11,
    "Agreement_Rank_2": 12,
    "Agreement_Rank_3": 13,
}

def _safe_int(v, default=-1):
    try:
        return int(float(v))
    except:
        return default

def _safe_score_04(v):
    x = _safe_int(v, default=-1)
    if x < 0:
        return -1
    if x > 4:
        return 4
    return x

def _bool01(v):
    return 1 if bool(v) else 0

def _yesno01(v):
    s = str(v).strip().lower()
    return 1 if s in ["1", "true", "yes", "y", "pass", "ok"] else 0

def _enc_conf(v):
    return CONF_MAP.get(str(v).strip().lower(), 0)

def _enc_cam(v):
    return CAM_VIEW_MAP.get(str(v).strip(), 0)

def _enc_road(v):
    return ROAD_TOPO_MAP.get(str(v).strip(), 0)

def _enc_vis(v):
    return VIS_MAP.get(str(v).strip().lower(), 0)

def _enc_basis(v):
    return BASIS_MAP.get(str(v).strip().lower(), 0)

def _enc_ab(v):
    s = str(v).strip().upper()
    if s == "A":
        return 1
    if s == "B":
        return 2
    return 0

def _enc_src(v):
    s = str(v).strip()
    if s in SRC_MAP:
        return SRC_MAP[s]
    # fallback (ë¶€ë¶„ ë¬¸ìì—´ ëŒ€ì‘)
    sl = s.lower()
    if "eunseok" in sl:
        return 1
    if "hyeong" in sl:
        return 2
    if "integrated" in sl:
        return 3
    if "agreement_rank_1" in sl:
        return 11
    if "agreement_rank_2" in sl:
        return 12
    if "agreement_rank_3" in sl:
        return 13
    return -1

def _enc_section(v):
    """
    section code ì˜ˆì‹œ:
      1 = section1/agreement-both
      2 = section2/eunseok ìš°ì„¸
      3 = section3/hyeongseon ìš°ì„¸
      4 = section4/third-answer
      0 = unknown
    """
    s = str(v).strip().lower()
    if ("section" in s and "1" in s) or ("agreement" in s and "1" in s):
        return 1
    if ("section" in s and "2" in s) or ("eunseok" in s) or ("ì€ì„" in s):
        return 2
    if ("section" in s and "3" in s) or ("hyeong" in s) or ("í˜•ì„ " in s):
        return 3
    if ("section" in s and "4" in s):
        return 4
    return 0

def _parse_code_any(v):
    """
    target_code_combinationì´ dict ë˜ëŠ” ë¬¸ìì—´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë‘˜ ë‹¤ ì²˜ë¦¬
    ë°˜í™˜: (p, f, a, b)
    """
    if isinstance(v, dict):
        return (
            _safe_int(v.get("place"), None),
            _safe_int(v.get("feature"), None),
            _safe_int(v.get("vehicle_a"), None),
            _safe_int(v.get("vehicle_b"), None),
        )
    # ë¬¸ìì—´ "(1, 11, 31, 34)" ê°™ì€ í˜•íƒœ ëŒ€ì‘
    nums = re.findall(r"\d+", str(v))
    if len(nums) >= 4:
        return tuple(int(x) for x in nums[:4])
    return (None, None, None, None)

def _contra_bits(axes):
    """
    place=1, feature=2, maneuver=4, role=8
    """
    if not isinstance(axes, list):
        axes = []
    bits = 0
    for a in axes:
        t = str(a).strip().lower()
        if t == "place":
            bits |= 1
        elif t == "feature":
            bits |= 2
        elif t == "maneuver":
            bits |= 4
        elif t == "role":
            bits |= 8
    return bits

def _count_vis_basis(vis_dict, basis_dict):
    # visibility counts
    vis_dict = vis_dict if isinstance(vis_dict, dict) else {}
    basis_dict = basis_dict if isinstance(basis_dict, dict) else {}

    vis_vals = [str(vis_dict.get(k, "")).strip().lower() for k in ["place", "feature", "maneuver", "role"]]
    basis_vals = [str(basis_dict.get(k, "")).strip().lower() for k in ["place", "feature", "maneuver", "role"]]

    vis_clear_cnt = sum(1 for x in vis_vals if x == "clear")
    vis_partial_cnt = sum(1 for x in vis_vals if x == "partial")
    vis_occ_cnt = sum(1 for x in vis_vals if x == "occluded")
    vis_unknown_cnt = sum(1 for x in vis_vals if x == "unknown" or x == "")

    basis_direct_cnt = sum(1 for x in basis_vals if x == "direct_visual")
    basis_partial_cnt = sum(1 for x in basis_vals if x == "partial_visual")
    basis_weak_cnt = sum(1 for x in basis_vals if x == "weak_inference")
    basis_unknown_cnt = sum(1 for x in basis_vals if x == "unknown" or x == "")

    return {
        "vis_clear_cnt": vis_clear_cnt,
        "vis_partial_cnt": vis_partial_cnt,
        "vis_occ_cnt": vis_occ_cnt,
        "vis_unknown_cnt": vis_unknown_cnt,
        "basis_direct_cnt": basis_direct_cnt,
        "basis_partial_cnt": basis_partial_cnt,
        "basis_weak_cnt": basis_weak_cnt,
        "basis_unknown_cnt": basis_unknown_cnt,
    }

def _counter_counts(counter_evidence):
    """
    counter_evidence íƒ€ì…ë³„ ê°œìˆ˜ (place/feature/maneuver/role/None)
    """
    ce = counter_evidence if isinstance(counter_evidence, list) else []
    out = {"ctr_cnt": 0, "ctr_place_cnt": 0, "ctr_feature_cnt": 0, "ctr_maneuver_cnt": 0, "ctr_role_cnt": 0, "ctr_none_cnt": 0}
    for item in ce:
        if not isinstance(item, dict):
            continue
        out["ctr_cnt"] += 1
        t = str(item.get("type", "")).strip().lower()
        if t == "place":
            out["ctr_place_cnt"] += 1
        elif t == "feature":
            out["ctr_feature_cnt"] += 1
        elif t == "maneuver":
            out["ctr_maneuver_cnt"] += 1
        elif t == "role":
            out["ctr_role_cnt"] += 1
        else:
            out["ctr_none_cnt"] += 1
    return out

def _argmax_hid_by_sum(h_rows, n_cands):
    """
    h_rows: {1:{...}, 2:{...}, 3:{...}}
    ë°˜í™˜:
      top1_idx, top2_idx, top1_sum, top2_sum
    tie-break: sum desc -> hard asc -> idx asc
    """
    items = []
    for i in range(1, n_cands + 1):
        r = h_rows.get(i, {})
        s = _safe_int(r.get("sum16"), -1)
        hard = _safe_int(r.get("hard"), 0)
        items.append((i, s, hard))

    if not items:
        return (0, 0, -1, -1)

    items_sorted = sorted(items, key=lambda x: (-x[1], x[2], x[0]))
    top1 = items_sorted[0]
    top2 = items_sorted[1] if len(items_sorted) >= 2 else (0, -1, 0)
    return (top1[0], top2[0], top1[1], top2[1])

def _pack_h(i, pruned_df, h_score_map, g_p, g_f, g_a, g_b):
    prefix = f"h{i}_"

    # í›„ë³´ê°€ ì—†ëŠ” ê²½ìš° (2ê°œ í›„ë³´ êµ¬ê°„ ëŒ€ë¹„)
    if len(pruned_df) < i:
        flat = {
            prefix + "valid": 0, prefix + "src": 0,
            prefix + "code_p": -1, prefix + "code_f": -1, prefix + "code_a": -1, prefix + "code_b": -1,
            prefix + "p": -1, prefix + "f": -1, prefix + "m": -1, prefix + "r": -1, prefix + "sum16": -1,
            prefix + "hard": 0,
            prefix + "contra_bits": 0, prefix + "contra_p": 0, prefix + "contra_f": 0, prefix + "contra_m": 0, prefix + "contra_r": 0,
            prefix + "vis_p": 0, prefix + "vis_f": 0, prefix + "vis_m": 0, prefix + "vis_r": 0,
            prefix + "basis_p": 0, prefix + "basis_f": 0, prefix + "basis_m": 0, prefix + "basis_r": 0,
            prefix + "clear_cnt": 0, prefix + "partial_cnt": 0, prefix + "occ_cnt": 0, prefix + "vis_unk_cnt": 0,
            prefix + "direct_cnt": 0, prefix + "basis_partial_cnt": 0, prefix + "weak_cnt": 0, prefix + "basis_unk_cnt": 0,
            prefix + "ctr_cnt": 0, prefix + "ctr_p_cnt": 0, prefix + "ctr_f_cnt": 0, prefix + "ctr_m_cnt": 0, prefix + "ctr_r_cnt": 0,
            prefix + "p_match": 0, prefix + "f_match": 0, prefix + "a_match": 0, prefix + "b_match": 0,
            prefix + "ab_match": 0, prefix + "exact": 0,
        }
        meta = {"sum16": -1, "hard": 0, "p": -1, "f": -1, "m": -1, "r": -1, "clear_cnt": 0, "direct_cnt": 0, "weak_cnt": 0, "exact": 0}
        return flat, meta

    row = pruned_df.iloc[i-1]
    expected_hid = str(row.get("hypothesis_id", f"H{i}"))
    expected_code = row.get("target_code_combination", row.get("code_combination", ""))
    expected_source = str(row.get("source_tag", ""))

    h = h_score_map.get(expected_hid, {}) if isinstance(h_score_map.get(expected_hid, {}), dict) else {}

    # scores
    s = h.get("scores", {}) if isinstance(h.get("scores", {}), dict) else {}
    p = _safe_score_04(s.get("place_score", -1))
    f = _safe_score_04(s.get("feature_score", -1))
    m = _safe_score_04(s.get("maneuver_score", -1))
    r = _safe_score_04(s.get("role_score", -1))
    sum16 = sum([x for x in [p, f, m, r] if x >= 0]) if any(x >= 0 for x in [p, f, m, r]) else -1

    # code parse
    code_src = expected_code if str(expected_code).strip() != "" else h.get("target_code_combination", "")
    hp, hf, ha, hb = _parse_code_any(code_src)

    # exact / matches
    p_match = 1 if (hp is not None and g_p is not None and hp == g_p) else 0
    f_match = 1 if (hf is not None and g_f is not None and hf == g_f) else 0
    a_match = 1 if (ha is not None and g_a is not None and ha == g_a) else 0
    b_match = 1 if (hb is not None and g_b is not None and hb == g_b) else 0
    ab_match = 1 if (a_match and b_match) else 0
    exact = 1 if (p_match and f_match and a_match and b_match) else 0

    # contradiction
    hard = 1 if bool(h.get("hard_contradiction", False)) else 0
    contra_bits = _contra_bits(h.get("contradiction_axes", []))

    # visibility / basis
    vis = h.get("visibility", {}) if isinstance(h.get("visibility", {}), dict) else {}
    basis = h.get("basis", {}) if isinstance(h.get("basis", {}), dict) else {}
    vb_cnts = _count_vis_basis(vis, basis)

    # counter evidence
    ce_cnts = _counter_counts(h.get("counter_evidence", []))

    # source
    src_val = str(h.get("source_tag", "")).strip() or expected_source
    src_code = _enc_src(src_val)

    flat = {
        prefix + "valid": 1, prefix + "src": src_code,
        prefix + "code_p": hp if hp is not None else -1,
        prefix + "code_f": hf if hf is not None else -1,
        prefix + "code_a": ha if ha is not None else -1,
        prefix + "code_b": hb if hb is not None else -1,

        prefix + "p": p, prefix + "f": f, prefix + "m": m, prefix + "r": r, prefix + "sum16": sum16,

        prefix + "hard": hard,
        prefix + "contra_bits": contra_bits,
        prefix + "contra_p": 1 if (contra_bits & 1) else 0,
        prefix + "contra_f": 1 if (contra_bits & 2) else 0,
        prefix + "contra_m": 1 if (contra_bits & 4) else 0,
        prefix + "contra_r": 1 if (contra_bits & 8) else 0,

        prefix + "vis_p": _enc_vis(vis.get("place", "")),
        prefix + "vis_f": _enc_vis(vis.get("feature", "")),
        prefix + "vis_m": _enc_vis(vis.get("maneuver", "")),
        prefix + "vis_r": _enc_vis(vis.get("role", "")),

        prefix + "basis_p": _enc_basis(basis.get("place", "")),
        prefix + "basis_f": _enc_basis(basis.get("feature", "")),
        prefix + "basis_m": _enc_basis(basis.get("maneuver", "")),
        prefix + "basis_r": _enc_basis(basis.get("role", "")),

        prefix + "clear_cnt": vb_cnts["vis_clear_cnt"],
        prefix + "partial_cnt": vb_cnts["vis_partial_cnt"],
        prefix + "occ_cnt": vb_cnts["vis_occ_cnt"],
        prefix + "vis_unk_cnt": vb_cnts["vis_unknown_cnt"],

        prefix + "direct_cnt": vb_cnts["basis_direct_cnt"],
        prefix + "basis_partial_cnt": vb_cnts["basis_partial_cnt"],
        prefix + "weak_cnt": vb_cnts["basis_weak_cnt"],
        prefix + "basis_unk_cnt": vb_cnts["basis_unknown_cnt"],

        prefix + "ctr_cnt": ce_cnts["ctr_cnt"],
        prefix + "ctr_p_cnt": ce_cnts["ctr_place_cnt"],
        prefix + "ctr_f_cnt": ce_cnts["ctr_feature_cnt"],
        prefix + "ctr_m_cnt": ce_cnts["ctr_maneuver_cnt"],
        prefix + "ctr_r_cnt": ce_cnts["ctr_role_cnt"],

        prefix + "p_match": p_match, prefix + "f_match": f_match,
        prefix + "a_match": a_match, prefix + "b_match": b_match,
        prefix + "ab_match": ab_match, prefix + "exact": exact,
    }

    meta = {
        "sum16": sum16, "hard": hard, "p": p, "f": f, "m": m, "r": r,
        "clear_cnt": vb_cnts["vis_clear_cnt"], "direct_cnt": vb_cnts["basis_direct_cnt"], "weak_cnt": vb_cnts["basis_weak_cnt"],
        "exact": exact
    }
    return flat, meta

# ê²°ê³¼ íŒŒì¼ì— í•œ ì¤„ì”© ì“°ê¸° ìœ„í•œ í—¬í¼ í•¨ìˆ˜
def save_result_to_csv(result_dict, file_path):
    file_exists = os.path.exists(file_path)
    # ë”•ì…”ë„ˆë¦¬ì˜ í‚¤ë¥¼ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì‚¬ìš©
    fieldnames = list(result_dict.keys())

    with open(file_path, 'a', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        # íŒŒì¼ì´ ì²˜ìŒ ìƒì„±ë˜ëŠ” ê²½ìš°ì—ë§Œ í—¤ë” ì‘ì„±
        if not file_exists:
            writer.writeheader()
        writer.writerow(result_dict)

def get_processed_videos(file_path):
    processed = set()
    if os.path.exists(file_path):
        try:
            df = pd.read_csv(file_path)
            if 'íŒŒì¼ëª…' in df.columns:
                processed = set(df['íŒŒì¼ëª…'].astype(str).tolist())
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜(ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}")
    return processed
    
def make_json(pred_str):
    """
    pred_str (ì˜ˆ: "(1, 11, 31, 34)")ì„ ì…ë ¥ë°›ì•„
    CSV íŒŒì¼ì˜ ID ì»¬ëŸ¼ë“¤ê³¼ ë§¤ì¹­ë˜ëŠ” í–‰ì„ ì°¾ì•„ JSON ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # 1. pred_str ë¬¸ìì—´ íŒŒì‹± (ì˜ˆ: "(1, 11, 31, 34)" -> 1, 11, 31, 34)
    try:
        # ast.literal_evalì„ ì‚¬ìš©í•˜ë©´ ê´„í˜¸ì™€ ì‰¼í‘œê°€ í¬í•¨ëœ ë¬¸ìì—´ì„ íŠœí”Œë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜í•©ë‹ˆë‹¤.
        p_id, f_id, a_id, b_id = ast.literal_eval(pred_str)
    except Exception as e:
        print(f"Error parsing pred_str: {e}")
        return None

    # 2. CSV íŒŒì¼ ë¡œë“œ (ì¸ì½”ë”©ì€ ìƒí™©ì— ë§ê²Œ ì¡°ì • ê°€ëŠ¥)
    df = mapping_df
    # ì»¬ëŸ¼ëª… ê³µë°± ì œê±°
    df.columns = df.columns.str.strip()

    # 3. ID ì¡°ê±´ì— ë§ëŠ” í–‰ í•„í„°ë§
    condition = (
        (df['ì‚¬ê³ ì¥ì†Œ_ID'] == p_id) &
        (df['ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID'] == f_id) &
        (df['Aì§„í–‰ë°©í–¥_ID'] == a_id) &
        (df['Bì§„í–‰ë°©í–¥_ID'] == b_id)
    )

    match = df[condition]

    if match.empty:
        print(f"í•´ë‹¹ ì¡°í•©({pred_str})ì— ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # ë§¤ì¹­ëœ ì²« ë²ˆì§¸ í–‰ ë°ì´í„° ì¶”ì¶œ
    row = match.iloc[0]

    # ê° í•­ëª©ì˜ ëª…ì¹­ (ë¬¸ìì—´ ì•ë’¤ ê³µë°± ì œê±°)
    place = str(row['ì‚¬ê³ ì¥ì†Œ']).strip()
    feature = str(row['ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•']).strip()
    a_action = str(row['Aì§„í–‰ë°©í–¥']).strip()
    b_action = str(row['Bì§„í–‰ë°©í–¥']).strip()

    # 4. JSON í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
    selected_explanation_case_json = {
        "accident_type_name": f"{place}, {feature}, {a_action}, {b_action}",
        "target_code_combination": pred_str,
        "place_name": place,
        "feature_name": feature,
        "a_vehicle_action": a_action,
        "b_vehicle_action": b_action,
        "negligence_ratio_a": int(row['ê³¼ì‹¤ë¹„ìœ¨A']),
        "negligence_ratio_b": int(row['ê³¼ì‹¤ë¹„ìœ¨B'])
    }

    return selected_explanation_case_json

def get_pred_from_type(accident_type):
    """
    ì‚¬ê³ ìœ í˜• ë²ˆí˜¸ë¥¼ ì…ë ¥ë°›ì•„ CSVì—ì„œ (ì¥ì†Œ, íŠ¹ì§•, Aê¸°ë™, Bê¸°ë™) ì½”ë“œë¥¼ ì°¾ì•„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        df_mapping = mapping_df
        #pd.read_csv(mapping_path, encoding='cp949')
        # 'ì‚¬ê³ ìœ í˜•' ì»¬ëŸ¼ì—ì„œ í•´ë‹¹ ë²ˆí˜¸ ì°¾ê¸°
        row = df_mapping[df_mapping['ì‚¬ê³ ìœ í˜•'] == accident_type]
        
        if not row.empty:
            p = int(row['ì‚¬ê³ ì¥ì†Œ_ID'].values[0])
            f = int(row['ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID'].values[0])
            a = int(row['Aì§„í–‰ë°©í–¥_ID'].values[0])
            b = int(row['Bì§„í–‰ë°©í–¥_ID'].values[0])
            return f"({p}, {f}, {a}, {b})"
        else:
            print(f"âš ï¸ ë§¤í•‘ í…Œì´ë¸”ì—ì„œ ì‚¬ê³ ìœ í˜• {accident_type}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
    except Exception as e:
        print(f"âš ï¸ C3D ë§¤í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

#ë§¤í•‘ ì •ì˜
label_env_name_mapping = {
    "roundabout_label": "VS_ì°¨ëŒ€ì°¨_ì˜ìƒ_íšŒì „êµì°¨ë¡œ",
    "4way_signal_label": "VS_ì°¨ëŒ€ì°¨_ì˜ìƒ_ì‚¬ê±°ë¦¬êµì°¨ë¡œ(ì‹ í˜¸ë“±ìˆìŒ)",
    "road_and_other_label": "VS_ì°¨ëŒ€ì°¨_ì˜ìƒ_ì°¨ë„ì™€ì°¨ë„ê°€ì•„ë‹Œì¥ì†Œ",
    "4way_no_signal_label": "VS_ì°¨ëŒ€ì°¨_ì˜ìƒ_ì‚¬ê±°ë¦¬êµì°¨ë¡œ(ì‹ í˜¸ë“±ì—†ìŒ)",
    "highway_label": "VS_ì°¨ëŒ€ì°¨_ì˜ìƒ_ê³ ì†ë„ë¡œ(ìë™ì°¨ì „ìš©ë„ë¡œ)í¬í•¨",
    "parking_lot_label": "VS_ì°¨ëŒ€ì°¨_ì˜ìƒ_ì£¼ì°¨ì¥(ë˜ëŠ”ì°¨ë„ê°€ì•„ë‹Œì¥ì†Œ)",
    "t_junction_label": "VS_ì°¨ëŒ€ì°¨_ì˜ìƒ_Tìí˜•êµì°¨ë¡œ",
    "straight_road_label": "VS_ì°¨ëŒ€ì°¨_ì˜ìƒ_ì§ì„ ë„ë¡œ",
}

model_analyzer = genai.GenerativeModel(model_name=current_model_name, system_instruction=system_instruction_explanation_direct)
def run_explan_test(video_stem, tone, video_file, pred_str, gt_str):
    selected_explanation_case_json = make_json(pred_str)
    
    tone_configs = {
        "í˜•ì„ ": {
            "guide": "ê°ê´€ì ì´ê³  ì „ë¬¸ì ì¸ ì–´ì¡°. 'ì…ë‹ˆë‹¤/ìŠµë‹ˆë‹¤' ì²´ ì‚¬ìš©.",
            "start_template": "ë³¸ ì‚¬ê³ ëŠ” {{ë‚ ì”¨}} ê¸°ìƒ ì¡°ê±´ì˜ {{ì‹œê°„ëŒ€}}ì— ë°œìƒí•œ ê±´ì…ë‹ˆë‹¤.",
            "end_template": "ì†í•´ë³´í—˜í˜‘íšŒ ê³¼ì‹¤ë¹„ìœ¨ ì¸ì •ê¸°ì¤€ì— ì˜ê±°í•˜ì—¬, {{Aí–‰ë™}} A ì°¨ëŸ‰ {{Aê³¼ì‹¤}}%, {{Bí–‰ë™}} B ì°¨ëŸ‰ {{Bê³¼ì‹¤}}%ë¡œ ìµœì¢… ì‚°ì •ë©ë‹ˆë‹¤."
        },
        "ì€ì„": {
            "guide": "ì•ˆíƒ€ê¹Œì›€ì„ ë‹´ì€ ë”°ëœ»í•œ ì–´ì¡°. ìš´ì „ìë¥¼ ìœ„ë¡œí•˜ëŠ” í‘œí˜„ í¬í•¨.",
            "start_template": "ì•ˆíƒ€ê¹ê²Œë„ ì´ ì‚¬ê³ ëŠ” ë‚ ì”¨ê°€ {{ë‚ ì”¨}} {{ì‹œê°„ëŒ€}}ì— ë°œìƒí•œ ì‚¬ê³ ì…ë‹ˆë‹¤.",
            "end_template": "ë§ì´ ë†€ë¼ì…¨ê² ì§€ë§Œ, ì†í•´ë³´í—˜í˜‘íšŒì˜ ê¸°ì¤€ì— ë”°ë¼ {{Aí–‰ë™}} A ì°¨ëŸ‰ì´ {{Aê³¼ì‹¤}}%, {{Bí–‰ë™}} B ì°¨ëŸ‰ì´ {{Bê³¼ì‹¤}}%ë¡œ ì‚°ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ë¶€ë”” ì˜ ë§ˆë¬´ë¦¬ë˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤."
        },
        "ìˆ˜ë¯¼": {
            "guide": "ì°¨ë¶„í•˜ê³  ì„¬ì„¸í•œ ì–´ì¡°. '~ë„¤ìš”/ë”ë¼ê³ ìš”' ë“± ë¶€ë“œëŸ¬ìš´ ì–´ë¯¸ í™œìš©.",
            "start_template": "{{weather}} ë‚ ì”¨ì˜ {{time_of_day}} ì‹œê°„ì— ì¼ì–´ë‚œ ì‚¬ê³  ë‹¹ì‹œ ìƒí™©ì„ ì‚´í´ë³´ë©´ ì¡°ê¸ˆ ì•ˆíƒ€ê¹Œìš´ ìƒí™©ì´ë„¤ìš”.",
            "end_template": "ë‹¹ì‹œ ìƒí™©ì„ ì¢…í•©í•´ ì†í•´ë³´í—˜í˜‘íšŒì˜ ê¸°ì¤€ê³¼ ë¹„êµí•´ë³´ë©´ {{Aí–‰ë™}} A ì°¨ëŸ‰ì´ {{Aê³¼ì‹¤}}%, {{Bí–‰ë™}} B ì°¨ëŸ‰ì´ {{Bê³¼ì‹¤}}%ì¸ ê²ƒìœ¼ë¡œ ë³´ì—¬ìš”. ì„¸ì‹¬í•œ ì£¼ì˜ê°€ í•„ìš”í•œ ì°°ë‚˜ì˜ ìˆœê°„ì´ì—ˆë˜ ê²ƒ ê°™ë„¤ìš”."
        }
    }
    
    tone_configs2 = {
        "í˜•ì„ ": {
            "guide": (
                "ë‹¹ì‹ ì€ ê°ì •ì´ ì—†ëŠ” AI ë¶„ì„ê´€ì…ë‹ˆë‹¤. 'ì…ë‹ˆë‹¤/í•©ë‹ˆë‹¤' ëŒ€ì‹  ë¬¸ì¥ì„ '~í•¨', '~ì„'ìœ¼ë¡œ ëë‚´ê±°ë‚˜ "
                "ë§¤ìš° ë”±ë”±í•œ ëª…ì‚¬í˜• ì¢…ê²°ì„ ì‚¬ìš©í•˜ì„¸ìš”. ìˆ˜ì‹ì–´ì™€ ê°ì •ì  ìœ„ë¡œë¥¼ 100% ì œê±°í•˜ê³  ì˜¤ì§ ë²•ê·œì™€ ë°ì´í„°ë§Œ ë‚˜ì—´í•˜ì‹­ì‹œì˜¤."
            ),
            "start_template": "[ë¶„ì„ ê°œìš”] ê¸°ìƒ {{weather}}, ì‹œê°„ëŒ€ {{time_of_day}}. ì‚¬ê³  ë°œìƒ ì •í™© ë³´ê³ í•¨.",
            "end_template": "[ìµœì¢… ì‚°ì •] í˜‘íšŒ ì¸ì •ê¸°ì¤€ ì¤€ìš©. {{a_vehicle_action}} A ì°¨ëŸ‰ {{negligence_ratio_a}}% : {{b_vehicle_action}} B ì°¨ëŸ‰ {{negligence_ratio_b}}%. ì´ìƒì„."
        },
        "ì€ì„": {
            "guide": (
                "ë‹¹ì‹ ì€ ì‚¬ê³ ë¥¼ ëª©ê²©í•˜ê³  ë„ˆë¬´ ê°€ìŠ´ ì•„íŒŒí•˜ëŠ” ì¹œí•œ í˜•/ì˜¤ë¹ ì…ë‹ˆë‹¤. "
                "ë¬¸ì¥ë§ˆë‹¤ 'ì •ë§ ë‹¹í™©í•˜ì…¨ê² ì–´ìš”', 'ì–´íœ´, ë‹¤ì¹˜ì§€ëŠ” ì•Šìœ¼ì…¨ë‚˜ìš”?' ê°™ì€ ê°íƒ„ì‚¬ì™€ ìœ„ë¡œë¥¼ ì•„ë‚Œì—†ì´ ë„£ìœ¼ì„¸ìš”. "
                "ë²•ì ì¸ ì´ì•¼ê¸°ë³´ë‹¤ ìš´ì „ìì˜ ë†€ë€ ë§ˆìŒì„ ë‹¬ë˜ëŠ” ë° ì§€ë©´ì˜ 70%ë¥¼ í• ì• í•˜ì„¸ìš”."
            ),
            "start_template": "ì•„ì´ê³ ... {{weather}} ë‚ ì”¨ì— {{time_of_day}}ì˜€ëŠ”ë° ê°‘ìê¸° ì´ëŸ° ì¼ì´ ìƒê²¨ì„œ ì–¼ë§ˆë‚˜ ë†€ë¼ì…¨ì„ê¹Œìš”.",
            "end_template": "ë§ì´ ì†ìƒí•˜ì‹œê² ì§€ë§Œ, ê¸°ì¤€ì´ ì´ë ‡ë‹¤ ë³´ë‹ˆ {{a_vehicle_action}} A ì°¨ëŸ‰ì´ {{negligence_ratio_a}}%, {{b_vehicle_action}} B ì°¨ëŸ‰ì´ {{negligence_ratio_b}}%ë¡œ ë‚˜ì™”ë„¤ìš”. í˜ë‚´ì‹œê³  ì˜ í•´ê²°ë˜ê¸¸ ì§„ì‹¬ìœ¼ë¡œ ë¹Œê²Œìš”."
        },
        "ìˆ˜ë¯¼": {
            "guide": (
                "ë‹¹ì‹ ì€ ì•„ì£¼ ì„¬ì„¸í•œ ê´€ì°°ìì…ë‹ˆë‹¤. '~ë„¤ìš”', '~ë”ë¼ê³ ìš”' ê°™ì€ ë¶€ë“œëŸ¬ìš´ ì¢…ê²° ì–´ë¯¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. "
                "ê²°ê³¼ë³´ë‹¤ëŠ” 'ì˜ìƒì„ ë³´ë‹ˆ ~í•˜ëŠ” ì°°ë‚˜ì˜€ëŠ”ë°'ì™€ ê°™ì´ ìƒí™©ì„ ì²œì²œíˆ ë³µê¸°í•´ì£¼ëŠ” ì„œìˆ  ë°©ì‹ì„ íƒí•˜ì„¸ìš”. "
                "ì—¬ì„±ìŠ¤ëŸ½ê³  ìš°ì•„í•˜ë©° ì°¨ë¶„í•œ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”."
            ),
            "start_template": "{{weather}} í•˜ëŠ˜ ì•„ë˜ {{time_of_day}}ì˜ ê³µê¸°ê°€ ëŠê»´ì§€ëŠ” ì˜ìƒì´ë„¤ìš”. ì¡°ê¸ˆì€ ì•„ì‰¬ìš´ ìˆœê°„ì´ ë‹´ê²¨ìˆë”ë¼ê³ ìš”.",
            "end_template": "ì „ì²´ì ì¸ íë¦„ì„ ë³´ë‹ˆ {{a_vehicle_action}} ì¤‘ì¸ A ì°¨ëŸ‰ì´ {{negligence_ratio_a}}%, {{b_vehicle_action}} ì¤‘ì¸ B ì°¨ëŸ‰ì´ {{negligence_ratio_b}}%ì˜ ë¹„ìœ¨ì´ ë‚˜ì™”ë„¤ìš”. ì°¸ ì•„ì‰¬ìš´ ì°°ë‚˜ì˜ ì‚¬ê³ ì˜€ë˜ ê²ƒ ê°™ì•„ìš”."
        }
    }
    
    selected_tone = tone_configs2[tone]
    
    prompt_explanation_direct = f"""
    ì•„ë˜ëŠ” êµí†µì‚¬ê³  ë¸”ë™ë°•ìŠ¤ ì˜ìƒì— ëŒ€í•´ íŒŒì´ì¬ í›„ì²˜ë¦¬ë¡œ ì´ë¯¸ í™•ì •ëœ ì‚¬ê³ ìœ í˜• ì •ë³´ì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì˜ ì—­í• ì€ ì´ í™•ì •ëœ ìœ í˜•ì„ ë°”íƒ•ìœ¼ë¡œ, ì˜ìƒì„ ì°¸ê³ í•´ ì‚¬ìš©ìì—ê²Œ ì½ê¸° ì‰¬ìš´ ì„¤ëª…ì„ ì‘ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

    [ì¤‘ìš”]
    - ìµœì¢… ìœ í˜•ì€ ì´ë¯¸ í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ë³€ê²½í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
    - í›„ë³´ ë¹„êµ, ì¬ì±„ì , ì¬ì„ íƒì„ í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
    - ë°˜ë“œì‹œ 'A ì°¨ëŸ‰', 'B ì°¨ëŸ‰'ìœ¼ë¡œë§Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤.
    - 'ë‚´ ì°¨ëŸ‰', 'ë¸”ë°• ì°¨ëŸ‰', 'ìƒëŒ€ ì°¨ëŸ‰', 'ê°€í•´ì°¨ëŸ‰', 'í”¼í•´ì°¨ëŸ‰' í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
    - ì˜ìƒì—ì„œ ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì€ ë‹¨ì •í•˜ì§€ ë§ê³  'í™•ì¸ ì–´ë ¤ì›€'ìœ¼ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

    [ì–´ì¡° ë° í…œí”Œë¦¿ ì§€ì¹¨]
    - ì „ì²´ì ì¸ ì–´ì¡°: {selected_tone['guide']}
    - ë¦¬í¬íŠ¸ ì‹œì‘ ë¬¸êµ¬(í˜•ì‹ ì—„ìˆ˜): "{selected_tone['start_template']}"
    - ë¦¬í¬íŠ¸ ë§ˆì¹¨ ë¬¸êµ¬(í˜•ì‹ ì—„ìˆ˜): "{selected_tone['end_template']}"
    - ì¤‘ê°„ ë‚´ìš©: ì‚¬ê³  ì •í™©ì„ ìƒì„¸íˆ ë¶„ì„í•˜ì—¬ ì‹œì‘ê³¼ ë ë¬¸êµ¬ ì‚¬ì´ì— ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜í•˜ì„¸ìš”.
    - ìœ„ ì§€ì¹¨ì„ ë°”íƒ•ìœ¼ë¡œ 'explanation_text'ë¥¼ ì‘ì„±í•˜ì„¸ìš”. 
    - ë°˜ë“œì‹œ ì‹œì‘/ë§ˆì¹¨ ë¬¸êµ¬ì˜ {{ }} ë¶€ë¶„ì„ ìœ„ ë°ì´í„°ì˜ ê°’ìœ¼ë¡œ ì •í™•íˆ ì¹˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.

    [ì¶”ê°€ ì§€ì‹œì‚¬í•­]
    - í…œí”Œë¦¿ ë‚´ì˜ ë°ì´í„°({{weather}}, {{time_of_day}} ë“±)ë¥¼ ë¬¸ì¥ì— ë„£ì„ ë•Œ, í•œêµ­ì–´ ì¡°ì‚¬(ì€/ëŠ”, ì´/ê°€, ì™€/ê³¼)ê°€ ë¬¸ë§¥ì— ë§ë„ë¡ ë‹¨ì–´ì˜ í˜•íƒœë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë³€í˜•í•˜ê±°ë‚˜ ë¬¸ì¥ì„ ë§¤ë„ëŸ½ê²Œ ë‹¤ë“¬ìœ¼ì„¸ìš”. 
    - ì˜ˆ: "ë§‘ìŒ ì•¼ê°„" (X) -> "ë§‘ì€ ë‚ ì”¨ì˜ ì•¼ê°„" ë˜ëŠ” "ë‚ ì”¨ê°€ ë§‘ì•˜ë˜ ì•¼ê°„" (O)

    [í™•ì •ëœ ìœ í˜• ì…ë ¥(JSON)]
    {selected_explanation_case_json}
    
    [ì¶œë ¥]
    {output_format_explanation_direct}
    """
    print(f"\nğŸš€ [ì„¤ëª… ì‹œì‘] {video_stem}")
    try:
        max_retries = 3
        attempt = 0
        response = None
        while attempt < max_retries:
            try:
                response = model_analyzer.generate_content([prompt_explanation_direct, video_file])
                break # ì„±ê³µ ì‹œ ë£¨í”„ íƒˆì¶œ

            except (http.client.RemoteDisconnected, Exception) as e:
                if ("429" in str(e) or "Quota" in str(e)):
                    print(f"ğŸš¨ í• ë‹¹ëŸ‰ ì´ˆê³¼! {current_model_name}ì˜ í• ë‹¹ëŸ‰ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
                    continue

                attempt += 1
                print(f"âš ï¸ {attempt}ì°¨ ì‹œë„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                time.sleep(10)

                if attempt >= max_retries:
                    print(f"âŒ ìµœì¢… ì‹¤íŒ¨: {video_stem}")
                    raise e

        vlm_text = response.text

        # 1. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì œê±° ë° JSON íŒŒì‹± (LLMì´ ```json ... ``` í˜•íƒœë¡œ ì¶œë ¥í•  ê²½ìš° ëŒ€ë¹„)
        clean_json_str = re.sub(r"```json\s*", "", vlm_text)
        clean_json_str = re.sub(r"```\s*$", "", clean_json_str).strip()

        vlm_json = json.loads(clean_json_str)

        # [ì¶”ê°€ëœ ë¡œì§] ë§Œì•½ ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ë©´ ì²« ë²ˆì§¸ ìš”ì†Œ(ë”•ì…”ë„ˆë¦¬)ë¥¼ ì„ íƒ
        if isinstance(vlm_json, list):
            if len(vlm_json) > 0:
                vlm_json = vlm_json[0]
            else:
                raise ValueError("Empty JSON list received")

        # ì¤‘ì²©ëœ JSON êµ¬ì¡°ì—ì„œ í•„ìš”í•œ ê°’ë“¤ì„ ì¶”ì¶œí•˜ì—¬ í‰íƒ„í™”(Flatten)í•©ë‹ˆë‹¤.
        obs = vlm_json.get("video_observation", {})
        scene = obs.get("scene_condition", {})
        road = obs.get("road_context", {})
        movement = obs.get("movement_observation", {})

        # ë¶ˆí™•ì‹¤ì„± ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        uncertainties = ", ".join(vlm_json.get("uncertainties", []))

        # 2. ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— append (ë”•ì…”ë„ˆë¦¬ í˜•íƒœ)
        # selected_explanation_case_jsonì— ìˆëŠ” ì •ë³´ì™€ VLMì´ ìƒì„±í•œ ìƒì„¸ ë¶„ì„ì„ í†µí•©í•©ë‹ˆë‹¤.
        results_exp_list=[]
        results_exp_list.append({
            "video_stem": video_stem,  # íŒŒì¼ëª… ë“± ì‹ë³„ì

            # Mapping ë°ì´í„° (ì´ì „ ë‹¨ê³„ì—ì„œ ë§Œë“  json ë°ì´í„° í™œìš©)
            #"gt_code_combination": gt_str,
            "target_code_combination": selected_explanation_case_json.get("target_code_combination"),
            "accident_type_name": selected_explanation_case_json.get("accident_type_name"),
            "negligence_ratio_a": selected_explanation_case_json.get("negligence_ratio_a"),
            "negligence_ratio_b": selected_explanation_case_json.get("negligence_ratio_b"),

            # VLM ìƒì„¸ ê´€ì°° ë°ì´í„° (JSON íŒŒì‹± ê²°ê³¼)
            "time_of_day": scene.get("time_of_day"),
            "weather": scene.get("weather"),
            "visibility_note": scene.get("visibility_note"),
            "intersection_type": road.get("intersection_type_observed"),
            "signal_observed": road.get("signal_observed"),
            "road_scale_hint": road.get("road_scale_hint"),
            "a_vehicle_observation": movement.get("a_vehicle_observation"),
            "b_vehicle_observation": movement.get("b_vehicle_observation"),
            "collision_moment": movement.get("collision_moment"),
            "uncertainties": uncertainties,

            # ìµœì¢… ì„¤ëª… ë¬¸êµ¬
            "explanation_text": vlm_json.get("explanation_text")
        })
    except Exception as e:
        print(str(e))
        return False
    return vlm_json.get("explanation_text")

model_scorer = genai.GenerativeModel(model_name=current_model_name, system_instruction=system_instruction_score_only)
def run_score_test(video_stem, idx, video_file, input_data):
    # 1. ë°ì´í„° ì¤€ë¹„ ë° ëª¨ë¸ ê²°ê³¼ ì¶”ì¶œ
    es_pred, hs_pred, total_pred1, total_pred2 = get_all_predictions_simple(input_data)
    
    sm_pred = None
    if "ìˆ˜ë¯¼" in input_data:
        accident_type = input_data["ìˆ˜ë¯¼"].get("accident_type")
        if accident_type is not None:
            sm_pred = get_pred_from_type(accident_type)
    
    gt_str = "" # ì„œë¹„ìŠ¤ ëª¨ë“œ
    
    # 2. ëª¨ë¸ í•©ì˜ ìƒíƒœ ê²°ì •
    if es_pred == hs_pred:
        is_agreement = "Agreement"
    elif es_pred == total_pred1:
        is_agreement = "Eunseok"
    elif hs_pred == total_pred1:
        is_agreement = "Hyeongseon"
    else:
        is_agreement = "Disagreement"

    # 3. ì¤‘ë³µì„ ì œê±°í•œ í›„ë³´ ë¦¬ìŠ¤íŠ¸ ìƒì„± (VLM ì±„ì  ëŒ€ìƒ)
    unique_preds = []
    candidates = [total_pred1, total_pred2, es_pred, hs_pred]
    if sm_pred:
        candidates.append(sm_pred)
    for p in candidates:
        if p not in unique_preds:
            unique_preds.append(p)

    # 4. res_data ìƒì„± (DataFrame êµ¬ì„±ì„ ìœ„í•œ ê¸°ì´ˆ ë°ì´í„°)
    res_data = []
    for i, pred in enumerate(unique_preds):
        nums = re.findall(r'\d+', str(pred))
        codes = [int(n) for n in nums[:4]] if len(nums) >= 4 else [0, 0, 0, 0]
        
        # ì¶œì²˜ íƒœê·¸ (ì˜ˆ: "Integrated1/Eunseok")
        tags = []
        if pred == total_pred1: tags.append("Integrated1")
        if pred == total_pred2: tags.append("Integrated2")
        if pred == es_pred: tags.append("Eunseok")
        if pred == hs_pred: tags.append("Hyeongseon")
        if pred == sm_pred: tags.append("Sumin")
        
        source_tag = "/".join(sorted(list(set(tags))))

        res_data.append({
            "code_combination": pred,
            "Rank": i + 1,
            "recommendation": f"Top-{i+1}",
            "place": codes[0], "feature": codes[1], "veh_a": codes[2], "veh_b": codes[3],
            "source_tag": source_tag
        })

    # 5. DataFrame ë° VLM ì…ë ¥ ì¤€ë¹„
    pruned_df = pd.DataFrame(res_data)
    g_p = g_f = g_a = g_b = None # ì •ë‹µ ë¯¸ì‚¬ìš© ëª¨ë“œ
    
    def get_korean_desc(row):
        try:
            # mapping_dfì—ì„œ 4ê°œ IDê°€ ëª¨ë‘ ì¼ì¹˜í•˜ëŠ” í–‰ ì°¾ê¸°
            match = mapping_df[
                (mapping_df['ì‚¬ê³ ì¥ì†Œ_ID'] == row['place']) & 
                (mapping_df['ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID'] == row['feature']) & 
                (mapping_df['Aì§„í–‰ë°©í–¥_ID'] == row['veh_a']) & 
                (mapping_df['Bì§„í–‰ë°©í–¥_ID'] == row['veh_b'])
            ]
            if not match.empty:
                r = match.iloc[0]
                return f"{r['ì‚¬ê³ ì¥ì†Œ']}, {r['ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•']}, {r['Aì§„í–‰ë°©í–¥']}, {r['Bì§„í–‰ë°©í–¥']}"
        except Exception as e:
        # ğŸš¨ ì¶”ê°€: ì—ëŸ¬ì˜ ì§„ì§œ ì›ì¸ì„ í„°ë¯¸ë„ì— ë¶‰ì€ìƒ‰ìœ¼ë¡œ ìƒì„¸íˆ ì¶œë ¥!
            print(f"âŒ [VLM ë‚´ë¶€ ì—ëŸ¬ ë°œìƒ] ({video_stem}): {e}")
            traceback.print_exc() 
            return False, total_pred1, gt_str, (es_pred, hs_pred, total_pred1, total_pred2, sm_pred, [], [])
    # ê° ê°€ì„¤ì— ëŒ€í•´ í•œê¸€ ì„¤ëª… ì»¬ëŸ¼ ìƒì„±
    pruned_df['korean_description'] = pruned_df.apply(get_korean_desc, axis=1)
    
    print(f"\nğŸš€ [ë¶„ì„ ì‹œì‘] {video_stem} (ìƒíƒœ: {is_agreement})")

    pruned_df = pruned_df.reset_index(drop=True)
    pruned_df['hypothesis_id'] = [f"H{i+1}" for i in range(len(pruned_df))]
    pruned_df['target_code_combination'] = pruned_df['code_combination']
    pruned_df['target'] = pruned_df.apply(
        lambda r: f"{r['code_combination']}: ({r['korean_description']})", axis=1
    )
    
    selected_candidates_json = pruned_df[['hypothesis_id', 'source_tag', 'target_code_combination', 'target', 'place', 'feature', 'veh_a', 'veh_b']].to_json(orient='records', force_ascii=False)
    
    print(selected_candidates_json)

    # 6. VLM í˜¸ì¶œ (Score-only)
    prompt_score_only = f"""
    ì•„ë˜ëŠ” êµí†µì‚¬ê³  ë¸”ë™ë°•ìŠ¤ ì˜ìƒì— ëŒ€í•œ í›„ë³´ ê°€ì„¤ ëª©ë¡ì…ë‹ˆë‹¤.
    ì´ë²ˆ ì‘ì—…ì€ ìµœì¢… ì„ íƒì´ ì•„ë‹ˆë¼, ê° í›„ë³´ì˜ ì‹œê°ì  ì¼ì¹˜ë„ ì±„ì (score-only)ì…ë‹ˆë‹¤.

    [ì…ë ¥ê°’ ìœ ì§€ ê·œì¹™]
    - hypothesis_id, target_code_combination, target, source_tagëŠ” ì…ë ¥ê°’ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì‹­ì‹œì˜¤. ì„ì˜ ìˆ˜ì • ê¸ˆì§€.
    - hypothesis_scoringì—ëŠ” ì…ë ¥ëœ ëª¨ë“  í›„ë³´ë¥¼ ë¹ ì§ì—†ì´ í¬í•¨í•˜ì‹­ì‹œì˜¤.

    [ì‹¤í–‰ ì§€ì‹œ]
    - ëª¨ë“  í›„ë³´ë¥¼ ê°™ì€ ê¸°ì¤€ìœ¼ë¡œ ì±„ì í•˜ì‹­ì‹œì˜¤.
    - ê° í›„ë³´ë§ˆë‹¤ counter_evidenceë¥¼ ìµœì†Œ 1ê°œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
    (ë°˜ì¦ì´ ì—†ìœ¼ë©´ {{"time":"None","type":"None","detail":"None"}} ì‚¬ìš©)
    - evidence / environment_cues / counter_evidence / axis_comparison.notes ë°°ì—´ì€ ê°ê° ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

    [ì¶”ê°€ ê´€ì°° ê¸°ì¤€: Place ê³„ì¸µ íŒë‹¨]
    - ì•„ë˜ ì§€ì¹¨ì€ place/feature ê´€ì°°ì„ ì •ë¦¬í•˜ê¸° ìœ„í•œ ì°¸ê³  ê¸°ì¤€ì…ë‹ˆë‹¤.
    - hard-ruleë¡œ ê°•ì œí•˜ì§€ ë§ê³ , ì˜ìƒì—ì„œ ì‹¤ì œë¡œ ë³´ì´ëŠ” ë‹¨ì„œë¥¼ ìš°ì„ í•˜ì‹­ì‹œì˜¤.
    {place_hierarchy_instruction}

    [í›„ë³´ ê°€ì„¤(JSON)]
    {selected_candidates_json}

    [ì¶œë ¥]
    {output_format_score_only}
    """

    try:
        response = model_scorer.generate_content([prompt_score_only, video_file])
        vlm_text = response.text
        clean_json_str = re.sub(r"```json\s*|```\s*", "", vlm_text).strip()
        vlm_json = json.loads(clean_json_str)
        if isinstance(vlm_json, list): vlm_json = vlm_json[0]

        h_scores = vlm_json.get("hypothesis_scoring", [])
        h_score_map = {str(h.get("hypothesis_id", "")).strip(): h for h in h_scores}

        # 7. ìƒì„¸ ë°ì´í„°(h_data) ë° ê°œë³„ ì ìˆ˜ ì¶”ì¶œ
        h_data = {}
        for i in range(1, 4): # H1, H2, H3 ëŒ€ì‘
            if len(pruned_df) >= i:
                row = pruned_df.iloc[i-1]
                h = h_score_map.get(row['hypothesis_id'], {})
                s = h.get("scores", {})
                
                # ì ìˆ˜ í•©ì‚° ë¡œì§
                scores = [int(float(s.get(k, -1))) for k in ["place_score", "feature_score", "maneuver_score", "role_score"]]
                raw_sum = sum(x for x in scores if x >= 0)
                
                h_data[f"ê°€ì„¤{i}_ì ìˆ˜í•©"] = raw_sum
                h_data[f"ê°€ì„¤{i}_ì…ë ¥ì½”ë“œ"] = row['code_combination']
                h_data[f"ê°€ì„¤{i}_ì¶œì²˜"] = row['source_tag']

        # 8. ìµœì¢… ë­í‚¹ ê²°ì • (VLM ì ìˆ˜ ê¸°ì¤€)
        # _pack_hì™€ _argmax_hid_by_sumëŠ” ì™¸ë¶€ ì •ì˜ëœ í—¬í¼ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        h1_flat, h1m = _pack_h(1, pruned_df, h_score_map, g_p, g_f, g_a, g_b)
        h2_flat, h2m = _pack_h(2, pruned_df, h_score_map, g_p, g_f, g_a, g_b)
        h3_flat, h3m = _pack_h(3, pruned_df, h_score_map, g_p, g_f, g_a, g_b)
        
        _hrows_rank = {1: h1m, 2: h2m, 3: h3m}
        top1_idx, top2_idx, top1_sum, top2_sum = _argmax_hid_by_sum(_hrows_rank, len(pruned_df))

        # --------------------------------------------------------
        # 9. [ì‚´ë ¤ë‘” ë¡œì§] results_short_list êµ¬ì„±ì„ ìœ„í•œ ë ˆì½”ë“œ ìƒì„±
        # --------------------------------------------------------
        visual_obs = vlm_json.get("visual_observation", {})
        pov_obs = vlm_json.get("pov_observation", {})
        role_id = vlm_json.get("role_identification", {})

        short_record = {
            "video_id": video_stem,
            "section_type": is_agreement,
            "n_cands": len(pruned_df),
            "top1_idx": top1_idx,
            "top1_sum16": top1_sum,
            "top2_sum16": top2_sum,
            "margin": top1_sum - top2_sum if top2_sum >= 0 else 0,
            "ego_pred": role_id.get("blackbox_is", "unknown"),
            "cam_view": pov_obs.get("camera_view", ""),
            # ê°€ì„¤ë³„ í”Œë˜íˆ°(Flattened) ë°ì´í„° ë³‘í•©
            **h1_flat, **h2_flat, **h3_flat
        }
        # ì´ short_recordë¥¼ ì™¸ë¶€ì˜ ë¦¬ìŠ¤íŠ¸ì— append í•˜ê±°ë‚˜ ë¦¬í„´ì— í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        # 10. ìµœì¢… ê²°ê³¼ê°’ êµ¬ì„±
        # final_pred_code = h_data.get(f"ê°€ì„¤{top1_idx}_ì…ë ¥ì½”ë“œ", total_pred1)
        
        if is_agreement == "Agreement":
            # í•©ì˜ ìƒíƒœë¼ë©´ VLM ì ìˆ˜ì™€ ê´€ê³„ì—†ì´ ì•Œê³ ë¦¬ì¦˜ì´ ë„ì¶œí•œ 1ìˆœìœ„(total_pred1)ë¥¼ ì„ íƒ
            # ë³´í†µ pruned_dfì˜ ì²« ë²ˆì§¸ í–‰(H1)ì´ total_pred1ì…ë‹ˆë‹¤.
            final_pred_code = total_pred1
        else:
            # ë¶ˆì¼ì¹˜ ìƒíƒœ(Eunseok/Hyeongseon/Disagreement)ì—ì„œë§Œ VLM ì ìˆ˜ë¥¼ ë”°ë¦„
            final_pred_code = h_data.get(f"ê°€ì„¤{top1_idx}_ì…ë ¥ì½”ë“œ", total_pred1)
        
        vlm_scores = [h_data.get(f"ê°€ì„¤{i}_ì ìˆ˜í•©", -1) for i in range(1, len(pruned_df)+1)]
        vlm_sources = pruned_df['source_tag'].tolist()
        
        model_results = (es_pred, hs_pred, total_pred1, total_pred2, sm_pred, vlm_scores, vlm_sources)

        return True, final_pred_code, gt_str, model_results

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ({video_stem}): {e}")
        return False, total_pred1, gt_str, (es_pred, hs_pred, total_pred1, total_pred2, sm_pred, [], [])
        
def run_score_test_old(video_stem, idx, video_file, input_data):
    #global model_scorer, current_model_name

    # 1. ë°ì´í„° ì¤€ë¹„ ë° ëª¨ë¸ ê²°ê³¼ ì¶”ì¶œ
    es_pred, hs_pred, total_pred1, total_pred2 = get_all_predictions_simple(input_data)
    gt_str = ""
    
    # 2. ëª¨ë¸ í•©ì˜ ìƒíƒœ ê²°ì •
    if es_pred == hs_pred:
        is_agreement = "Agreement"
        return False, [total_pred1, total_pred2], gt_str # í•©ì˜ ì‹œ ì¦‰ì‹œ ë°˜í™˜
    
    if es_pred == total_pred1:
        is_agreement = "Eunseok"
    elif hs_pred == total_pred1:
        is_agreement = "Hyeongseon"
    else:
        is_agreement = "Disagreement"

    # 3. ì¤‘ë³µì„ ì œê±°í•œ í›„ë³´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    unique_preds = []
    for p in [total_pred1, total_pred2, es_pred, hs_pred]:
        if p not in unique_preds:
            unique_preds.append(p)

    # 4. res_data ìƒì„± (KeyError ë°©ì§€ì˜ í•µì‹¬: ëª¨ë“  ì»¬ëŸ¼ì„ ì—¬ê¸°ì„œ ìƒì„±)
    res_data = []
    for i, pred in enumerate(unique_preds):
        nums = re.findall(r'\d+', str(pred))
        codes = [int(n) for n in nums[:4]] if len(nums) >= 4 else [0, 0, 0, 0]

        res_data.append({
            "code_combination": pred,
            "Rank": i + 1,
            "recommendation": f"Top-{i+1}",
            "place": codes[0],
            "feature": codes[1],
            "veh_a": codes[2],
            "veh_b": codes[3],
            "source_tag": "Integrated" if pred == total_pred1 else ("Eunseok" if pred == es_pred else "Hyeongseon")
        })

    # 5. DataFrame ìƒì„± (ì´ì œ pruned_dfëŠ” í•­ìƒ place, feature ë“±ì˜ ì»¬ëŸ¼ì„ ê°€ì§)
    pruned_df = pd.DataFrame(res_data)
    
    # [ì¤‘ìš”] ê¸°ì¡´ì˜ if is_agreement == "Eunseok": ... ë¡œ ì‹œì‘í•˜ëŠ” í•„í„°ë§ ì½”ë“œë“¤ì€ 
    # ì—¬ê¸°ì„œ ëª¨ë‘ ì‚­ì œí•´ì•¼ í•©ë‹ˆë‹¤. ì´ë¯¸ ìœ„ì—ì„œ í•„ìš”í•œ í›„ë³´ë§Œ ë‹´ì•˜ìŠµë‹ˆë‹¤.

    # 6. í›„ì† ë¡œì§ì„ ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™” (g_p ì—ëŸ¬ ë°©ì§€)
    g_p = g_f = g_a = g_b = None 

    print(f"\nğŸš€ [ë¶„ì„ ì‹œì‘] {video_stem} (ìƒíƒœ: {is_agreement})")

    # 7. ê°€ì„¤ ID ë¶€ì—¬ ë° ê·œê²©í™”
    pruned_df = pruned_df.reset_index(drop=True)
    pruned_df['hypothesis_id'] = [f"H{i+1}" for i in range(len(pruned_df))]
    pruned_df['target_code_combination'] = pruned_df['code_combination']
    
    # ì´ì œ 'place' ì»¬ëŸ¼ì´ í™•ì‹¤íˆ ì¡´ì¬í•˜ë¯€ë¡œ ì•„ë˜ applyê°€ ì„±ê³µí•©ë‹ˆë‹¤.
    pruned_df['target'] = pruned_df.apply(
        lambda r: f"{r['code_combination']}: ({r['place']}, {r['feature']}, {r['veh_a']}, {r['veh_b']})", axis=1
    )
    
    # 4. VLMì— ì „ë‹¬í•  ì»¬ëŸ¼ë§Œ ì¶”ì¶œí•˜ì—¬ JSON ë³€í™˜
    vlm_input_cols = ['hypothesis_id', 'source_tag', 'target_code_combination', 'target', 'place', 'feature', 'veh_a', 'veh_b']
    selected_candidates_json = pruned_df[vlm_input_cols].to_json(orient='records', force_ascii=False)

    # 5. í›„ì²˜ë¦¬ë¥¼ ìœ„í•œ ID ë§¤í•‘ í…Œì´ë¸” ë¯¸ë¦¬ ìƒì„±
    id_to_numeric_map = dict(zip(pruned_df['hypothesis_id'], pruned_df['target_code_combination']))

    prompt_score_only = f"""
    ì•„ë˜ëŠ” êµí†µì‚¬ê³  ë¸”ë™ë°•ìŠ¤ ì˜ìƒì— ëŒ€í•œ í›„ë³´ ê°€ì„¤ ëª©ë¡ì…ë‹ˆë‹¤.
    ì´ë²ˆ ì‘ì—…ì€ ìµœì¢… ì„ íƒì´ ì•„ë‹ˆë¼, ê° í›„ë³´ì˜ ì‹œê°ì  ì¼ì¹˜ë„ ì±„ì (score-only)ì…ë‹ˆë‹¤.

    [ì…ë ¥ê°’ ìœ ì§€ ê·œì¹™]
    - hypothesis_id, target_code_combination, target, source_tagëŠ” ì…ë ¥ê°’ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì‹­ì‹œì˜¤. ì„ì˜ ìˆ˜ì • ê¸ˆì§€.
    - hypothesis_scoringì—ëŠ” ì…ë ¥ëœ ëª¨ë“  í›„ë³´ë¥¼ ë¹ ì§ì—†ì´ í¬í•¨í•˜ì‹­ì‹œì˜¤.

    [ì‹¤í–‰ ì§€ì‹œ]
    - ëª¨ë“  í›„ë³´ë¥¼ ê°™ì€ ê¸°ì¤€ìœ¼ë¡œ ì±„ì í•˜ì‹­ì‹œì˜¤.
    - ê° í›„ë³´ë§ˆë‹¤ counter_evidenceë¥¼ ìµœì†Œ 1ê°œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
    (ë°˜ì¦ì´ ì—†ìœ¼ë©´ {{"time":"None","type":"None","detail":"None"}} ì‚¬ìš©)
    - evidence / environment_cues / counter_evidence / axis_comparison.notes ë°°ì—´ì€ ê°ê° ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

    [ì¶”ê°€ ê´€ì°° ê¸°ì¤€: Place ê³„ì¸µ íŒë‹¨]
    - ì•„ë˜ ì§€ì¹¨ì€ place/feature ê´€ì°°ì„ ì •ë¦¬í•˜ê¸° ìœ„í•œ ì°¸ê³  ê¸°ì¤€ì…ë‹ˆë‹¤.
    - hard-ruleë¡œ ê°•ì œí•˜ì§€ ë§ê³ , ì˜ìƒì—ì„œ ì‹¤ì œë¡œ ë³´ì´ëŠ” ë‹¨ì„œë¥¼ ìš°ì„ í•˜ì‹­ì‹œì˜¤.
    {place_hierarchy_instruction}

    [í›„ë³´ ê°€ì„¤(JSON)]
    {selected_candidates_json}

    [ì¶œë ¥]
    {output_format_score_only}
    """

    if selected_candidates_json=="[]" or selected_candidates_json == "{}":
        print("csv íŒŒì‹± ì˜¤ë¥˜")
        return False, "(-1,-1,-1,-1)", gt_str
    try:
        max_retries = 3
        attempt = 0
        response = None
        while attempt < max_retries:
            try:
                response = model_scorer.generate_content([prompt_score_only, video_file])
                break # ì„±ê³µ ì‹œ ë£¨í”„ íƒˆì¶œ

            except (http.client.RemoteDisconnected, Exception) as e:
                if ("429" in str(e) or "Quota" in str(e)):
                    print(f"ğŸš¨ í• ë‹¹ëŸ‰ ì´ˆê³¼! {current_model_name}ì˜ í• ë‹¹ëŸ‰ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
                    continue

                attempt += 1
                print(f"âš ï¸ {attempt}ì°¨ ì‹œë„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                time.sleep(10)

                if attempt >= max_retries:
                    print(f"âŒ ìµœì¢… ì‹¤íŒ¨: {video_stem}")
                    raise e

        vlm_text = response.text

        # 1. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì œê±° ë° JSON íŒŒì‹± (LLMì´ ```json ... ``` í˜•íƒœë¡œ ì¶œë ¥í•  ê²½ìš° ëŒ€ë¹„)
        clean_json_str = re.sub(r"```json\s*", "", vlm_text)
        clean_json_str = re.sub(r"```\s*$", "", clean_json_str).strip()

        vlm_json = json.loads(clean_json_str)

        # [ì¶”ê°€ëœ ë¡œì§] ë§Œì•½ ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ë©´ ì²« ë²ˆì§¸ ìš”ì†Œ(ë”•ì…”ë„ˆë¦¬)ë¥¼ ì„ íƒ
        if isinstance(vlm_json, list):
            if len(vlm_json) > 0:
                vlm_json = vlm_json[0]
            else:
                raise ValueError("Empty JSON list received")

        # score-onlyì—ì„œëŠ” hypothesis_scoringë§Œ ì‚¬ìš©
        h_scores = vlm_json.get("hypothesis_scoring", [])
        if not isinstance(h_scores, list):
            h_scores = []

        # hypothesis_id ê¸°ì¤€ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì°¾ê¸° ìœ„í•œ dict
        h_score_map = {}
        for h in h_scores:
            h_id = str(h.get("hypothesis_id", "")).strip()
            if h_id:
                h_score_map[h_id] = h

        # í›„ë³´/GT íŒŒì‹±ìš© í•¨ìˆ˜
        def parse_code(code_str):
            nums = re.findall(r'\d+', str(code_str))
            return [int(n) for n in nums] if len(nums) >= 4 else [None, None, None, None]

        # GT íŒŒì‹±
        #g_p, g_f, g_a, g_b = parse_code(gt_str)

        # score-only ë‹¨ê³„ì—ì„œëŠ” ìµœì¢… ì„ íƒ ì—†ìŒ
        # ëŒ€ì‹  í›„ë³´ë³„ ì ìˆ˜ë§Œ ì €ì¥í•˜ê³ , ë‚˜ì¤‘ì— íŒŒì´ì¬ì—ì„œ í›„ì²˜ë¦¬ ê°€ëŠ¥í•˜ë„ë¡ ì¶©ë¶„íˆ ê¸°ë¡
        h_data = {}

        # pruned_df ê¸°ì¤€ìœ¼ë¡œ ê¸°ëŒ€ í›„ë³´(H1/H2/H3) ìˆœì„œëŒ€ë¡œ ì €ì¥ (VLM ìˆœì„œ ê¼¬ì—¬ë„ ì•ˆì „)
        for i in range(1, 4):
            if len(pruned_df) >= i:
                row = pruned_df.iloc[i-1]
                expected_hid = str(row.get("hypothesis_id", f"H{i}"))
                expected_code = str(row.get("target_code_combination", row.get("code_combination", "")))
                expected_target = str(row.get("target", ""))
                expected_source = str(row.get("source_tag", ""))

                h = h_score_map.get(expected_hid, {})

                s = h.get("scores", {}) if isinstance(h.get("scores", {}), dict) else {}
                sr = h.get("score_reasons", {}) if isinstance(h.get("score_reasons", {}), dict) else {}

                vis = h.get("visibility", {}) if isinstance(h.get("visibility", {}), dict) else {}
                basis = h.get("basis", {}) if isinstance(h.get("basis", {}), dict) else {}

                contr_axes = h.get("contradiction_axes", [])
                if not isinstance(contr_axes, list):
                    contr_axes = []
                contr_axes_str = ",".join([str(x) for x in contr_axes])

                def _safe_score(v):
                    try:
                        return int(float(v))
                    except:
                        return -1

                p_score = _safe_score(s.get("place_score", -1))
                f_score = _safe_score(s.get("feature_score", -1))
                m_score = _safe_score(s.get("maneuver_score", -1))
                r_score = _safe_score(s.get("role_score", -1))

                # ë°˜ì¦ ë¬¸ìì—´ ì§ë ¬í™”
                ce_list = h.get("counter_evidence", [])
                if not isinstance(ce_list, list):
                    ce_list = []
                ce_str = " | ".join([
                    f"[{ce.get('time','')}/{ce.get('type','')}] {ce.get('detail','')}"
                    for ce in ce_list if isinstance(ce, dict)
                ]) if ce_list else "[None/None] None"

                # score-only ë‹¨ê³„ìš© í•©ê³„ (í›„ì²˜ë¦¬ ì „ ì„ì‹œ ë¶„ì„ìš©)
                raw_sum = sum([x for x in [p_score, f_score, m_score, r_score] if isinstance(x, int) and x >= 0])

                h_data[f"ê°€ì„¤{i}_ID"] = expected_hid
                h_data[f"ê°€ì„¤{i}_ì…ë ¥ì½”ë“œ"] = expected_code
                h_data[f"ê°€ì„¤{i}_ì…ë ¥íƒ€ê²Ÿ"] = expected_target
                h_data[f"ê°€ì„¤{i}_ì¶œì²˜"] = expected_source

                # VLMì´ targetì„ ê·¸ëŒ€ë¡œ ì•ˆ ëŒë ¤ì¤˜ë„ ì…ë ¥ ê¸°ì¤€ìœ¼ë¡œ ë³´ì¡´
                h_data[f"ê°€ì„¤{i}_VLMíƒ€ê²Ÿ"] = h.get("target", "")
                h_data[f"ê°€ì„¤{i}_í•˜ë“œëª¨ìˆœ"] = h.get("hard_contradiction", False)

                h_data[f"ê°€ì„¤{i}_ì ìˆ˜_P"] = p_score
                h_data[f"ê°€ì„¤{i}_ì ìˆ˜_F"] = f_score
                h_data[f"ê°€ì„¤{i}_ì ìˆ˜_M"] = m_score
                h_data[f"ê°€ì„¤{i}_ì ìˆ˜_R"] = r_score
                h_data[f"ê°€ì„¤{i}_ì ìˆ˜í•©(0~16)"] = raw_sum

                h_data[f"ê°€ì„¤{i}_ê·¼ê±°_P"] = sr.get("place_reason", "")
                h_data[f"ê°€ì„¤{i}_ê·¼ê±°_F"] = sr.get("feature_reason", "")
                h_data[f"ê°€ì„¤{i}_ê·¼ê±°_M"] = sr.get("maneuver_reason", "")
                h_data[f"ê°€ì„¤{i}_ê·¼ê±°_R"] = sr.get("role_reason", "")

                h_data[f"ê°€ì„¤{i}_ë°˜ì¦"] = ce_str
                h_data[f"ê°€ì„¤{i}_ëª¨ìˆœì¶•"] = contr_axes_str

                h_data[f"ê°€ì„¤{i}_ê°€ì‹œì„±_P"] = vis.get("place", "")
                h_data[f"ê°€ì„¤{i}_ê°€ì‹œì„±_F"] = vis.get("feature", "")
                h_data[f"ê°€ì„¤{i}_ê°€ì‹œì„±_M"] = vis.get("maneuver", "")
                h_data[f"ê°€ì„¤{i}_ê°€ì‹œì„±_R"] = vis.get("role", "")

                h_data[f"ê°€ì„¤{i}_ê·¼ê±°ê°•ë„_P"] = basis.get("place", "")
                h_data[f"ê°€ì„¤{i}_ê·¼ê±°ê°•ë„_F"] = basis.get("feature", "")
                h_data[f"ê°€ì„¤{i}_ê·¼ê±°ê°•ë„_M"] = basis.get("maneuver", "")
                h_data[f"ê°€ì„¤{i}_ê·¼ê±°ê°•ë„_R"] = basis.get("role", "")
            else:
                # í›„ë³´ê°€ 2ê°œì¸ êµ¬ê°„ ëŒ€ë¹„ ë¹ˆì¹¸ ì±„ìš°ê¸°
                h_data[f"ê°€ì„¤{i}_ID"] = ""
                h_data[f"ê°€ì„¤{i}_ì…ë ¥ì½”ë“œ"] = ""
                h_data[f"ê°€ì„¤{i}_ì…ë ¥íƒ€ê²Ÿ"] = ""
                h_data[f"ê°€ì„¤{i}_ì¶œì²˜"] = ""
                h_data[f"ê°€ì„¤{i}_VLMíƒ€ê²Ÿ"] = ""
                h_data[f"ê°€ì„¤{i}_í•˜ë“œëª¨ìˆœ"] = ""
                h_data[f"ê°€ì„¤{i}_ì ìˆ˜_P"] = ""
                h_data[f"ê°€ì„¤{i}_ì ìˆ˜_F"] = ""
                h_data[f"ê°€ì„¤{i}_ì ìˆ˜_M"] = ""
                h_data[f"ê°€ì„¤{i}_ì ìˆ˜_R"] = ""
                h_data[f"ê°€ì„¤{i}_ì ìˆ˜í•©(0~16)"] = ""
                h_data[f"ê°€ì„¤{i}_ê·¼ê±°_P"] = ""
                h_data[f"ê°€ì„¤{i}_ê·¼ê±°_F"] = ""
                h_data[f"ê°€ì„¤{i}_ê·¼ê±°_M"] = ""
                h_data[f"ê°€ì„¤{i}_ê·¼ê±°_R"] = ""
                h_data[f"ê°€ì„¤{i}_ë°˜ì¦"] = ""
                h_data[f"ê°€ì„¤{i}_ëª¨ìˆœì¶•"] = ""
                h_data[f"ê°€ì„¤{i}_ê°€ì‹œì„±_P"] = ""
                h_data[f"ê°€ì„¤{i}_ê°€ì‹œì„±_F"] = ""
                h_data[f"ê°€ì„¤{i}_ê°€ì‹œì„±_M"] = ""
                h_data[f"ê°€ì„¤{i}_ê°€ì‹œì„±_R"] = ""
                h_data[f"ê°€ì„¤{i}_ê·¼ê±°ê°•ë„_P"] = ""
                h_data[f"ê°€ì„¤{i}_ê·¼ê±°ê°•ë„_F"] = ""
                h_data[f"ê°€ì„¤{i}_ê·¼ê±°ê°•ë„_M"] = ""
                h_data[f"ê°€ì„¤{i}_ê·¼ê±°ê°•ë„_R"] = ""

        # score-onlyì—ì„œë„ ê´€ì°° í•„ë“œëŠ” ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ìˆìœ¼ë©´ ì €ì¥ (ì—†ìœ¼ë©´ ë¹ˆê°’)
        visual_obs = vlm_json.get("visual_observation", {}) if isinstance(vlm_json.get("visual_observation", {}), dict) else {}
        role_id = vlm_json.get("role_identification", {}) if isinstance(vlm_json.get("role_identification", {}), dict) else {}
        pov_obs = vlm_json.get("pov_observation", {}) if isinstance(vlm_json.get("pov_observation", {}), dict) else {}

        ego_is = role_id.get("blackbox_is", "unknown")
        #gt_other = gt_ab_dict.get(video_stem, "Unknown").upper()
        #gt_ego_true = 'B' if 'A' in gt_other else ('A' if 'B' in gt_other else 'Unknown')
        ego_is_clean = 'A' if 'A' in str(ego_is).upper() else ('B' if 'B' in str(ego_is).upper() else 'Unknown')
        #is_ego_correct = "Pass" if (gt_ego_true == ego_is_clean and gt_ego_true != "Unknown") else "Fail"

        # ìµœì¢… ì„ íƒ/ì •ë‹µ ì ì¤‘ì€ ì•„ì§ ê³„ì‚° ì•ˆí•¨ (í›„ì²˜ë¦¬ ì „)
        results_list= []
        results_list.append({
            "íŒŒì¼ëª…": video_stem,
            "êµ¬ê°„ìœ í˜•": is_agreement,
            #"GT_ì½”ë“œ": gt_str,

            # score-only ë‹¨ê³„ ìƒíƒœ
            "í›„ë³´ê°œìˆ˜": len(pruned_df),
            #"í›„ë³´ë‚´ì •ë‹µì¡´ì¬": "Yes" if is_gt_in_candidates else "No",

            # ê´€ì°°/ë³´ì¡° ì •ë³´
            "ì¹´ë©”ë¼ì‹œì ì¶”ì •": pov_obs.get("camera_view", ""),
            "ë„ë¡œí† í´ë¡œì§€ì¶”ì •": visual_obs.get("road_topology_guess", ""),
            "ê¸°ë™ê´€ì°°_Ego": visual_obs.get("ego_maneuver_guess", ""),
            "ê¸°ë™ê´€ì°°_Other": visual_obs.get("other_vehicle_maneuver_guess", ""),
            "ì¶©ëŒê¸°í•˜": visual_obs.get("collision_geometry", ""),
            #"GT_ë¸”ë°•ì°¨ëŸ‰": gt_ego_true,
            "VLM_ë¸”ë°•ì°¨ëŸ‰": ego_is_clean,
            #"ë¸”ë°•ì‹ë³„_ì„±ê³µì—¬ë¶€": is_ego_correct,

            # ì¶”ê°€ í•„ë“œ
            "ì¹´ë©”ë¼ì‹œì ì¶”ì •_ì‹ ë¢°ë„": pov_obs.get("confidence", ""),
            "ê´€ì°°ì‹ ë¢°ë„": visual_obs.get("observation_confidence", ""),
            "ì—­í• ë§¤í•‘ê·¼ê±°": role_id.get("mapping_reason", ""),
            "ì—­í• ì‹ë³„ì‹ ë¢°ë„": role_id.get("confidence", ""),

            # ë””ë²„ê¹…ìš© ì›ë¬¸/íŒŒì‹± ìƒíƒœ
            "íŒŒì‹±ìƒíƒœ": "OK",
            "ëª¨ë¸": current_model_name,

            # ê°€ì„¤ë³„ ìƒì„¸
            **h_data
        })

        # --------------------------------------------------------
        # build compact candidates (H1/H2/H3)
        # --------------------------------------------------------
        h1_flat, h1m = _pack_h(1, pruned_df, h_score_map, g_p, g_f, g_a, g_b)
        h2_flat, h2m = _pack_h(2, pruned_df, h_score_map, g_p, g_f, g_a, g_b)
        h3_flat, h3m = _pack_h(3, pruned_df, h_score_map, g_p, g_f, g_a, g_b)

        # rank by sum (tie: hard ì‘ì€ í›„ë³´ ìš°ì„ )
        _hrows_rank = {1: h1m, 2: h2m, 3: h3m}
        top1_idx, top2_idx, top1_sum, top2_sum = _argmax_hid_by_sum(_hrows_rank, int(len(pruned_df)))

        # small helper for delta
        def _delta(a, b, invalid=-99):
            return (a - b) if (a is not None and b is not None and a >= 0 and b >= 0) else invalid

        # --------------------------------------------------------
        # short analysis row append (main block stays compact)
        # --------------------------------------------------------
        results_short_list = []
        results_short_list.append({
            # meta
            "schema_ver": 2,
            "row_id": f"{video_stem}__{_enc_section(is_agreement)}",
            "video_id": video_stem,
            "section_code": _enc_section(is_agreement),   # 1/2/3/4/0
            "n_cands": int(len(pruned_df)),
            #"gt_in_cands": 1 if is_gt_in_candidates else 0,
            "parse_ok": 1,

            # GT split
            #"gt_p": g_p if g_p is not None else -1,
            #"gt_f": g_f if g_f is not None else -1,
            #"gt_a": g_a if g_a is not None else -1,
            #"gt_b": g_b if g_b is not None else -1,

            # observation / role (encoded)
            "cam_view": _enc_cam(pov_obs.get("camera_view", "ë¶ˆëª…")),
            "cam_conf": _enc_conf(pov_obs.get("confidence", "")),
            "road_topo": _enc_road(visual_obs.get("road_topology_guess", "ë¶ˆëª…")),
            "obs_conf": _enc_conf(visual_obs.get("observation_confidence", "")),
            "role_conf": _enc_conf(role_id.get("confidence", "")),
            #"ego_gt": _enc_ab(gt_ego_true),
            "ego_pred": _enc_ab(ego_is_clean),
            #"ego_pass": 1 if str(is_ego_correct).lower() == "pass" else 0,

            # flattened candidates
            **h1_flat, **h2_flat, **h3_flat,

            # baseline (H1)
            "base_idx": 1,
            "base_exact": h1m["exact"],

            # rank summary (pure score sum)
            "top1_idx": top1_idx,
            "top2_idx": top2_idx,
            "top1_sum16": top1_sum,
            "top2_sum16": top2_sum,
            "top12_margin_sum": (top1_sum - top2_sum) if (top1_sum >= 0 and top2_sum >= 0) else -99,
            "top1_exact": (h1m["exact"] if top1_idx == 1 else h2m["exact"] if top1_idx == 2 else h3m["exact"] if top1_idx == 3 else 0),
            "top2_exact": (h1m["exact"] if top2_idx == 1 else h2m["exact"] if top2_idx == 2 else h3m["exact"] if top2_idx == 3 else 0),

            # commonly used H2 vs H1 deltas (threshold searchìš©)
            "h2m1_p": _delta(h2m["p"], h1m["p"]),
            "h2m1_f": _delta(h2m["f"], h1m["f"]),
            "h2m1_m": _delta(h2m["m"], h1m["m"]),
            "h2m1_r": _delta(h2m["r"], h1m["r"]),
            "h2m1_sum16": _delta(h2m["sum16"], h1m["sum16"]),
            "h2m1_clear_cnt": h2m["clear_cnt"] - h1m["clear_cnt"],
            "h2m1_direct_cnt": h2m["direct_cnt"] - h1m["direct_cnt"],
            "h2m1_weak_cnt": h2m["weak_cnt"] - h1m["weak_cnt"],

            # optional: H3 vs H1 / H3 vs H2ë„ ìì£¼ ë³´ë©´ ì¶”ê°€
            "h3m1_sum16": _delta(h3m["sum16"], h1m["sum16"]),
            "h3m2_sum16": _delta(h3m["sum16"], h2m["sum16"]),

            "model": current_model_name,
        })

        #print(f"{idx}: [{video_stem}] ì²˜ë¦¬ ì™„ë£Œ - GT: {gt_str}")#/ VLM: {vlm_codes_str} ({exact_match})")

    except KeyboardInterrupt:
        print(f"\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨: {video_stem}")
        raise  # ë£¨í”„ ì „ì²´ë¥¼ ë©ˆì¶”ë ¤ë©´ ë‹¤ì‹œ raise

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ({video_stem}): {e}")
        return False, "(-1,-1,-1,-1)", gt_str

    final_pred_code = h_data.get(f"ê°€ì„¤{top1_idx}_ì…ë ¥ì½”ë“œ", "(-1,-1,-1,-1)")
    return True, final_pred_code, gt_str



'''
sec1_samples = ['bb_1_160910_vehicle_241_26225', 'bb_1_160116_vehicle_222_29116', 'bb_1_180222_vehicle_148_238', 'bb_1_160614_vehicle_112_113', 'bb_1_120318_vehicle_113_157', 'bb_1_220827_vehicle_256_50486', 'bb_1_170120_vehicle_233_22160', 'bb_1_150517_vehicle_37_150', 'bb_1_210210_vehicle_212_45839', 'bb_1_181104_vehicle_195_096']

target_samples = sec1_samples

output_csv_path = "/content/drive/MyDrive/260224_ai/4th_experiment_results_score.csv"
output_short_csv_path = "/content/drive/MyDrive/260224_ai/4th_experiment_results_score_short.csv"
output_exp_csv_path = "/content/drive/MyDrive/260224_ai/4th_experiment_results_exp.csv"
processed_in_this_env = get_processed_videos(output_exp_csv_path)
video_files = [v for v in target_samples if v not in processed_in_this_env] # ë¯¸ì²˜ë¦¬ íŒŒì¼ë§Œ ì¶”ì¶œ


input_c_path = "/content/input.csv"

print(f"{len(processed_in_this_env)}, {len(video_files)}")

for i, sample in enumerate(video_files):
    try:
        v_path, l_path, _ = find_file_paths(sample)

        process_single_json_to_csv(l_path, input_c_path, csv_type_path)

        if not input_c_path:
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {sample}")
        else:
            video_file = genai.upload_file(path=v_path)
            while video_file.state.name == "PROCESSING":
                time.sleep(2)
                video_file = genai.get_file(video_file.name)

        run, pred_str, gt_str = run_score_test(sample, i, video_file, input_c_path)

        if results_list and False:
            last_result = results_list[-1]
            save_result_to_csv(last_result, output_csv_path)
            last_result_short = results_short_list[-1]
            save_result_to_csv(last_result_short, output_short_csv_path)

        # API í˜¸ì¶œ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
        time.sleep(3)

        #pred_str = "(-1,-1,-1,-1)"
        run2 = run_explan_test(sample, i, video_file, pred_str, gt_str)

        if results_exp_list and run2:
            last_exp_result = results_exp_list[-1]
            save_result_to_csv(last_exp_result, output_exp_csv_path)

        # API í˜¸ì¶œ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
        
    except Exception as e:
        print(f"âŒ {sample} ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ(ê±´ë„ˆëœ€): {e}")
        continue

    finally:
        if 'video_file' in locals():
            try:
                video_file.delete()
            except Exception as e:
                print("ë¹„ë””ì˜¤ ì‚­ì œ ì‹¤íŒ¨")
'''

